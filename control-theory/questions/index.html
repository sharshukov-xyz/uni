<!DOCTYPE html>
<html>

  <head>
    <meta charset=utf-8>
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <title>Вопросы &mdash; Теория управления</title>

    <link href="/assets/css/styles.css" rel="stylesheet">
    <script defer src="/assets/js/core.js"></script>
    <script defer src="/assets/js/questions.js"></script>
    <script defer src="/assets/js/controls.js"></script>

    <link rel="stylesheet" href="/assets/katex/katex.min.css">
    <script defer src="/assets/katex/katex.min.js"></script>
    <script defer src="/assets/katex/auto-render.min.js"></script>

    <script>
      document.addEventListener("DOMContentLoaded", function () {
        renderMathInElement(document.body, {
          // customised options
          // • auto-render specific keys, e.g.:
          delimiters: [
            { left: '$$', right: '$$', display: true },
            { left: '$', right: '$', display: false },
            { left: '\\(', right: '\\)', display: false },
            { left: '\\[', right: '\\]', display: true }
          ],
          // • rendering keys, e.g.:
          throwOnError: false
        });
      });
    </script>
  </head>

  <body>
    <h1 id="title">Вопросы &mdash; Теория управления</h1>
    <nav>
      <a href="/">Домой</a>
      <a href="/control-theory">Теория управления</a>
    </nav>

    <div class="controls">
      <button onclick="HideQuestions()">Скрыть вопросы</button>
      <button onclick="ShowQuestions()">Показать вопросы</button>
      <button onclick="HideAnswers()">Скрыть ответы</button>
      <button onclick="ShowAnswers()">Показать ответы</button>
      <button onclick="HideProofs()">Скрыть доказательства</button>
      <button onclick="ShowProofs()">Показать доказательства</button>
      <button onclick="ShowRandomElement(HideQuestions)">
        Показать случайный вопрос
      </button>
    </div>

    <div class="proof-type">
      Показывать
      <select id="select-proof-type" name="select-proof-type">
        <option value="proofs">доказательства полностью</option>
        <option value="ideas">только идеи доказательств</option>
      </select>
    </div>

    <div style="display:none">
      $\global\def\at#1#2{\left. #1 \right\rvert_{#2}}$
      $\global\def\abs#1{\left\lvert #1 \right\rvert}$
      $\global\def\norm#1{\left\lVert #1 \right\rVert}$

      $\global\def\dp#1#2{#1 \cdot #2\,}$
      $\global\def\vp#1#2{#1 \times #2\,}$

      $\global\def\dv#1#2{\frac{d #1}{d #2}}$
      $\global\def\pd#1#2{\frac{\partial #1}{\partial #2}}$
      $\global\def\pdv2#1#2{\frac{\partial^2 #1}{\partial #2^2}}$
      $\global\def\ppdv#1#2#3{\frac{\partial^2 #1}{\partial #2 \partial #3}}$

      $\global\def\paren#1{\left( #1 \right)}$

      $\global\def\mbox#1{\text{#1}}$

      $\global\def\div{\text{div}\,}$
      $\global\def\dsum{\displaystyle\sum\,}$
      $\global\def\grad{\text{grad}\,}$
      $\global\def\rot{\text{rot}\,}$

      $\global\def\bydef#1{\overset{\mathrm{def}}{#1}}$
      $\global\def\vb#1{\textbf{#1}}$

      $\global\def\rddots{\cdot^{\displaystyle \cdot^{\displaystyle \cdot}}}$

      $\global\def\op#1{\mathrm{#1}\,}$

      $\global\def\diag{\mathrm{diag}\,}$
      $\global\def\rank{\mathrm{rank}\,}$
      $\global\def\Sp{\,\mathrm{Sp}\,}$
      $\global\def\proj{\mathrm{proj}}$
      $\global\def\grad{\,\mathrm{grad}\,}$
      $\global\def\const{\text{const}\,}$
      $\global\def\res{\text{res}\,}$
      $\global\def\Res{\text{Res}\,}$
      $\global\def\Lin{\,\text{Lin}\,}$
      $\global\def\Re{\text{Re}\,}$
      $\global\def\Im{\text{Im}\,}$
      $\global\def\ch{\text{ch}\,}$
      $\global\def\sh{\text{sh}\,}$
      $\global\def\tg{\mathrm{tg}\,}$
      $\global\def\argtg{\text{argtg}\,}$
    </div>

    <ol id="questions">
      <h2 class="subtitle">
        1. Программные управления в линейных системах. Лемма о представлении
        семейства допустимых управлений
      </h2>

      <li class="question">
        <div class="name">
          Определение: управление
        </div>
        <div class="content">
          Рассмотрим замкнутую и ограниченную область $U \subset \mathbb{R}^r$.

          <div class="definition">
            Функция
            \[
            u : [t_0; t_1] \to U
            \]
            называется <i>управлением</i>, а $U$ &mdash;
            <i>множеством управления</i>.
          </div>
        </div>
      </li>

      <li class="question">
        <div class="name">
          В чём заключается прямая задача динамики?
        </div>
        <div class="content">
          <div class="answer">
            Прямая задача: решить задачу Коши
            \[
            \begin{aligned}
            \dot{x}(t) &= F(t, x, u) \\
            x(t_0) &= x_0
            \end{aligned}
            \]
            и найти такое управление $u = u(t, x)$, чтобы система имела
            желаемый характер.
          </div>
        </div>
      </li>

      <li class="question">
        <div class="name">
          В чём заключается обратная задача динамики?
        </div>
        <div class="content">
          <div class="answer">
            Обратная задача: замкнуть систему
            \[
            \begin{aligned}
            \dot{x}(t) &= F(t, x, u) \\
            x(t_0) &= x_0
            \end{aligned}
            \]
            известным управлением $u = \widetilde{u}(t, x)$ и найти её решение.
          </div>
        </div>
      </li>

      <li class="question">
        <div class="name">
          Определение: фазовый вектор объекта
        </div>
        <div class="content">
          <div class="definition">
            <i>Фазовым вектором</i> объекта называется всякий вектор $x(t)$,
            обладающий следующими свойствами:
            <ol>
              <li>
                Компоненты $x_i(t)$ характеризуют состояние объекта в момент
                времени $t$;
              </li>

              <li>
                Каждое начальное состояние $x(t_0) = x^0$ единственным образом
                определяет значения $x(t) = x(t, t_0, x^0)$ для всех
                рассматриваемых моментов времени $t$.
              </li>
            </ol>
          </div>
        </div>
      </li>

      <li class="question">
        <div class="name">
          Определение: допустимое управление
        </div>
        <div class="content">
          <div class="definition">
            Функцию $u(t) \in U$ называют допустимым управлением,
            если она
            <ol>
              <li>
                задана на $[0;T]$;
              </li>

              <li>
                кусочно-непрерывна;
              </li>

              <li>
                её интенсивность ограничена:
                \[
                \chi[u] = \int\limits_0^T u^*(\tau) u(\tau) d \tau \lt \infty.
                \]
              </li>
            </ol>
          </div>
        </div>
      </li>

      <li class="question">
        <div class="name">
          Формулировка общей задачи об управлении с введённым ограничением
        </div>
        <div class="content">
          Требуется найти допустимое управление $u(t)$, переводящее систему
          \[
          \dot{x}(t) = F(t, x, u),
          \]
          из состояния $x(0) = x^0$ в состояние $x(T) = x^1$, и при этом
          интенсивность управления $\chi[u]$ была бы ограничена.
        </div>
      </li>

      <li class="question">
        <div class="name">
          Определение: программное управление
        </div>
        <div class="content">
          <div class="definition">
            Допустимое управление $u(t)$ называется <i>программным</i>, если
            оно переводит систему
            \[
            \dot{x}(t) = F(t, x, u),
            \]
            из состояния $x(0) = x^0$ в состояние $x(T) = x^1$.
          </div>
        </div>
      </li>

      <li class="question">
        <div class="name">
          Общее решение неоднородной линейной системы ОДУ в форме Коши
        </div>
        <div class="content">
          Рассмотрим линейную систему ОДУ:
          \[
          \dot{x} = P(t) x + Q(t) u(t) + f(t).
          \]
          Пусть $Y$ &mdash; фундаментальная матрица соответствующей однородной
          системы, нормированная в нуле. Тогда можно записать
          <i>общее решение неоднородной системы в форме Коши</i>:
          \[
          x(t, 0, x_0) = Y(t) \left(
          x_0 + \int\limits_0^t Y^{-1}(\tau) \left[Q(\tau) u(\tau) +
          f(\tau)\right] d\tau \right).
          \]
        </div>
      </li>

      <li class="question">
        <div class="name">
          Постановка задачи о нахождении программного управления для линейной
          системы ОДУ
        </div>
        <div class="content">
          Рассмотрим линейную систему ОДУ:
          \[
          \dot{x} = P(t) x + Q(t) u(t) + f(t).
          \]

          <div class="problem">
            Требуется найти управление $u(t) \in U$, переводящее систему из
            состояния $x(0) = x_0$ в состояние $x(T) = x_1$.
          </div>

          <div class="solution">
            Рассмотрим общее решение исходной системы в форме Коши:
            \[
            x(t, 0, x_0) = Y(t) \left(
            x_0 + \int\limits_0^t Y^{-1}(\tau) \left[Q(\tau) u(\tau) +
            f(\tau)\right] d\tau \right).
            \]
            Если $u(t)$ &mdash; программное, то
            \[
            x(T, 0, x_0) = x_1,
            \]
            то есть поиск программного решения
            сводится к поиску решения, удовлетворяющего этому равенству.

            <p>
            Найдём из него, что
            \[
            x_1 = Y(T) \paren{x_0 + \int\limits_0^T Y^{-1}(\tau) Q(\tau)
            u(\tau) d\tau + \int\limits_0^T Y^{-1}(\tau) f(\tau) d\tau}.
            \]
            Обозначим $B(t) := Y^{-1}(t) Q(t)$ и домножим уравнение слева на
            $Y^{-1}(T)$:
            \[
            \int\limits_0^T B(\tau) u(\tau) d\tau = Y^{-1}(T) x_1 - x_0
            - \int\limits_0^T Y^{-1}(\tau) f(\tau) d\tau.
            \]
            Правая часть &mdash; некоторая константа, которую можно обозначить
            как $\eta$, тогда
            \[
            \int\limits_0^T B(\tau) u(\tau) d\tau = \eta,
            \]
            то есть если $u(t)$ удовлетворяет этому интегральному уравнению, то
            оно программное.
            </p>
          </div>
        </div>
      </li>

      <li class="question">
        <div class="name">
          Теорема: интегральный критерий линейной независимости функций
        </div>
        <div class="content">
          Пусть на отрезке $[0; T]$ заданы $m$ вектор-функций $x^1(t), \dots,
          x^m(t)$ размерности $r$. Рассмотрим матрицу
          \[
          B(t) = \left(
          \begin{array}{c}
          x^1(t) \\
          \vdots \\
          x^m(t)
          \end{array}
          \right), \qquad \dim B(t) = m \times r.
          \]

          <div class="theorem">
            Функции $x^1(t), \dots, x^m(t)$ линейно независимы на $[0; T]$
            тогда и только тогда, когда интегральная матрица
            \[
            A = \int\limits_0^T B(t) B^*(t) dt
            \]
            положительно определена.

            <div class="idea">
              Необходимость и достаточность доказываются от противного,
              пользуясь тем фактом, что
              \[
              \gamma^* A \gamma = \int\limits_0^T \norm{\gamma^* B(\tau)} d\tau.
              \]
            </div>

            <div class="proof">
              <div class="necessity">
                От противного: пусть $x^i$ &mdash; ЛНЗ на $[0;T]$, но $A$ не
                является положительно определённой. Тогда существует $\gamma
                \neq 0$ такое, что
                \[
                \begin{aligned}
                0 &= \gamma^* A \gamma \\
                &= \int\limits_0^T \gamma^* B(\tau) B^*(\tau) \gamma d\tau \\
                &= \int\limits_0^T \norm{\gamma^* B(\tau)}^2 d\tau,
                \end{aligned}
                \]
                но тогда
                \[
                \exists \gamma \neq 0: \quad \gamma^* B(t) \equiv 0,
                \quad t \in [0;T],
                \]
                откуда следует линейная зависимость функций $x^i$ на $[0; T]$
                &mdash; получили противоречие.
              </div>

              <div class="sufficiency">
                От противного. Пусть $A$ положительно определена, но $x^i$
                линейно зависимы на $[0; T]$. Тогда
                \[
                \exists \gamma \neq 0: \quad \gamma^* B(t) \equiv 0,
                \quad t \in [0; T],
                \]
                но тогда
                \[
                \begin{aligned}
                \gamma^* A \gamma
                &= \int\limits_0^T \gamma^* B(\tau) B^*(\tau) \gamma d\tau \\
                &= \int\limits_0^T \norm{\gamma^* B(\tau)}^2 d\tau = 0
                \end{aligned}
                \]
                для некоторого ненулевого $\gamma$, откуда следует, что $A$ не
                является положительно определённой &mdash; получили
                противоречие.
              </div>
            </div>
          </div>
        </div>
      </li>

      <li class="question">
        <div class="name">
          Лемма о нахождении семейства допустимых управлений
        </div>
        <div class="content">
          <div class="lemma">
            Если допустимое управление $u(t)$ линейной системы
            \[
            \dot{x} = P(t) x + Q(t) u(t) + f(t)
            \]
            существует, то оно представимо в виде
            \[
            u(t) = B^*(t) C + V(t), \qquad B(t) := Y^{-1}(t) Q(t),
            \]
            где
            <ul>
              <li>
                $Y(t)$ &mdash; нормированная в нуле фундаментальная матрица
                соответствующей однородной системы
              </li>

              <li>
                $C$ &mdash; постоянный вектор, подлежащий определению
              </li>

              <li>
                $V(t)$ &mdash; $r$-мерная векторная функция, удовлетворяющая
                условию ортогональности:
                \[
                \int\limits_0^T B(\tau) V(\tau) d\tau = 0.
                \]
              </li>
            </ul>

            <div class="idea">
              Подставим представление
              \[
              u(t) = B^*(t) C + V(t)
              \]
              в уравнение ортогональности, докажем совместность системы от
              противного (предположив, что $\rank A \lt \rank (A, \eta)$),
              воспользовавшись теоремой Фредгольма:
              \[
              A x = b \text{ совместна} \iff \exists \gamma \neq 0:
              \gamma^* a = 0, \; \text{ но } \; \gamma^* b \neq 0.
              \]
            </div>

            <div class="proof">
              Пусть существует допустимое управление $u(t) \in U$. Тогда
              утверждение леммы справедливо, если
              \[
              \int\limits_0^T B(\tau) \left[u(\tau) - B^*(\tau) C \right]
              d\tau = 0.
              \]
              Перепишем это равенство в виде
              \[
              \int\limits_0^T B(\tau) u(\tau) d\tau
              = \int\limits_0^T B(\tau) B^*(\tau) d\tau \cdot C;
              \]
              рассмотрим его как СЛАУ относительно неизвестного вектора $C$:
              \[
              AC = b,
              \]
              где
              \[
              A := \int\limits_0^T B(\tau) B^*(\tau) d\tau,
              \quad b := \int\limits_0^T B(\tau) u(\tau) d\tau.
              \]

              <p>
              Из
              <a
                href="https://ru.wikipedia.org/wiki/Теорема_Кронекера_—_Капелли"
                target="_blank">
                теоремы Кронекера-Капелли
              </a> известно, что система совместна тогда и только тогда, когда
              $\rank A = \rank (A, b)$.
              </p>

              <p>
              Предположим, что система несовместна, то есть $\rank A \lt \rank
              (A, b)$. Тогда по теореме Фредгольма найдётся вектор $\gamma \neq
              0$, ортогональный всем столбцам матрицы $A$, но не ортогональный
              вектору $b$, то есть
              \[
              \gamma^* A = 0, \quad \gamma^* b \neq 0.
              \]
              Отсюда следует, что
              \[
              \begin{aligned}
              0 &= \gamma^* A \gamma \\
              &= \gamma^* \int\limits_0^T B(\tau) B^*(\tau) d\tau \cdot
              \gamma \\
              &= \int\limits_0^T \gamma^* B(\tau) B^*(\tau) \gamma d\tau \\
              &= \int\limits_0^T \norm{\gamma^* B(\tau)}^2 d\tau = 0,
              \end{aligned}
              \]
              то есть $\gamma^* B(t) \equiv 0$. Но тогда
              \[
              \gamma^* b = \gamma^* \int\limits_0^T B(\tau) u(\tau) d\tau
              = \int\limits_0^T \overbrace{\gamma^* B(\tau)}^{\equiv 0} u(\tau)
              d\tau = 0,
              \]
              что противоречит выбору $\gamma$. Значит, $\rank A = \rank
              (A,b)$, то есть система совместна.
              </p>

              <p>
              Решая эту систему, находим вектор $C$, при котором разность
              $u(t) - B^*(t) C$ удовлетворяет условию
              \[
              \int\limits_0^T B(\tau) \left[u(\tau) - B^*(\tau) C \right]
              d\tau = 0.
              \]
              Введя обозначение $V(t) := u(t) - B^*(t) C$, получаем, что
              \[
              u(t) = B^*(t) C + V(t).
              \]
              </p>

              <div class="remark">
                В случае поиска программного управления $u(t)$, переводящего
                систему из $x(0) = x_0$ в $x(T) = x_1$, известен коэффициент
                \[
                b = \int\limits_0^T B(\tau) u(\tau) d\tau = \eta,
                \]
                где
                \[
                \eta \bydef = Y^{-1}(T) x_1 - x_0 - \int\limits_0^T Y^{-1}(\tau)
                f(\tau) d\tau,
                \]
                поэтому СЛАУ для нахождения $C$ запишется в виде
                \[
                AC = \eta.
                \]
              </div>
            </div>
          </div>
        </div>
      </li>

      <h2 class="subtitle">
        2. Управляемость пары точек и критерии полной управляемости линейной
        системы
      </h2>

      <li class="question">
        <div class="name">
          Определение: управляемая пара точек
        </div>
        <div class="content">
          Рассмотрим систему
          \[
          \dot{x} = P(t) x + Q(t) u + f(t).
          \]

          <div class="definition">
            Пара состояний $(x_0, x_1)$ называется <i>управляемой</i> на
            $[0; T]$, если для неё существует программное управление вида
            \[
            u(t) = B^*(t) C + V(t), \quad \text{причём}
            \quad \int\limits_0^T B(\tau) V(\tau) d\tau = 0.
            \]
          </div>
        </div>
      </li>

      <li class="question">
        <div class="name">
          Теорема об управляемости пары точек
        </div>
        <div class="content">
          Рассмотрим систему
          \[
          \dot{x} = P(t) x + Q(t) u + f(t).
          \]
          <div class="theorem">
            Пара точек $(x_0, x_1)$ управляема на $[0; T]$ тогда и только
            тогда, когда
            \[
            \rank A = \rank (A, \eta),
            \]
            где
            <ul>
              <li>
                ${\displaystyle A := \int\limits_0^T B(\tau) B^*(\tau) d\tau}$,
              </li>

              <li>
                ${\displaystyle B := Y^{-1}(t) Q(t)}$.
              </li>

              <li>
                ${\displaystyle \eta := Y^{-1}(T) x_1 - x_0
                - \int\limits_0^T Y^{-1}(\tau) f(\tau) d\tau}$.
              </li>
            </ul>

            <div class="idea">
              Проверяется подстановкой в
              \[
              \int\limits_0^T B(\tau) u(\tau) d\tau = \eta,
              \]
              используя теорему Кронекера-Капелли.
            </div>

            <div class="proof">
              <div class="necessity">
                Пусть пара $(x_0, x_1)$ &mdash; управляема, то есть существует
                программное управление $u(t)$. Из леммы о представлении
                семейства допустимых управлений следует, что оно представимо в
                виде
                \[
                u(t) = B^*(t) C + V(t), \quad \text{причём}
                \quad \int\limits_0^T B(\tau) V(\tau) d\tau = 0,
                \]
                и удовлетворяет уравнению
                \[
                \int\limits_0^T B(\tau) u(\tau) d\tau = \eta,
                \]
                следовательно, $C$ является решением СЛАУ
                \[
                AC = \eta,
                \]
                то есть эта СЛАУ совместна, поэтому по теореме Кронекера-Капелли
                \[
                \rank A = \rank (A, \eta).
                \]
              </div>

              <div class="sufficiency">
                Пусть $\rank A = \rank (A, \eta)$, тогда по теореме
                Кронекера-Капелли СЛАУ
                \[
                AC = \eta
                \]
                совместна, следовательно, существует $\overline{C}$ &mdash;
                решение этой СЛАУ. Тогда по лемме о представлении семейства
                допустимых управлений управление
                \[
                u(t) = B^*(t) \overline{C} + V(t), \quad \text{причём} \quad
                \int\limits_0^T B(\tau) V(\tau) d\tau = 0,
                \]
                удовлетворяет уравнению
                \[
                \int\limits_0^T B(\tau) u(\tau) d\tau = \eta,
                \]
                то есть является программным для пары точек $(x_0, x_1)$.
              </div>
            </div>
          </div>
        </div>
      </li>

      <li class="question">
        <div class="name">
          Определение: полностью управляемая линейная система
        </div>
        <div class="content">
          <div class="definition">
            Систему
            \[
            \dot{x} = P(t) x + Q(t) u + f(t)
            \]
            называют <i>полностью управляемой на $[0; T]$</i>, если любая пара
            точек $(x_0, x_1)$ управляема.
          </div>
        </div>
      </li>

      <li class="question">
        <div class="name">
          Теорема о полной управляемости линейной системы
        </div>
        <div class="content">
          <div class="theorem">
            Система
            \[
            \dot{x} = P(t) x + Q(t) u + f(t)
            \]
            полностью управляема на $[0; T]$ тогда и только тогда, когда
            \[
            \rank A = n, \quad (\text{или} \; \det A \neq 0),
            \]
            где
            <ul>
              <li>
                ${\displaystyle A := \int\limits_0^T B(\tau) B^*(\tau) d\tau}$;
              </li>

              <li>
                ${\displaystyle B := Y^{-1}(t) Q(t)}$.
              </li>
            </ul>

            <div class="idea">
              <div class="necessity">
                Если система полностью управляма, то система $AC = \eta$ должна
                быть разрешима при любом $\eta$, а это возможно тогда и только
                тогда, когда $A$ невырождена.
              </div>

              <div class="sufficiency">
                Если $A$ невырождена, то для любой пары точек $(x_0, x_1)$ можно
                найти $C$, то есть построить программное управление вида
                $u = B^*(t) C + V(t)$, откуда следует полная управляемость
                системы.
              </div>
            </div>

            <div class="proof">
              <div class="necessity">
                Пусть система полностью управляема, тогда $\eta$ может
                принимать любые значения в силу произвольности пары
                $(x_0, x_1)$, следовательно, система
                \[
                AC = \eta
                \]
                совместна для любого $\eta$. Отсюда следует невырожденность
                матрицы $A$.
              </div>

              <div class="sufficiency">
                Пусть матрица $A$ невырождена, тогда для любого вектора
                $\eta = \eta(x_0, x_1)$ можно найти
                \[
                \widetilde{C} = A^{-1} \eta,
                \]
                то есть для любой пары точек $(x_0, x_1)$ можно построить
                программное управление
                \[
                u(t) = B^*(t) \widetilde{C} + V(t),
                \]
                следовательно, система является полностью управляемой на
                $[0; T]$.
              </div>
            </div>
          </div>
        </div>
      </li>

      <li class="question">
        <div class="name">
          Свойства матрицы ${\displaystyle A = \int\limits_0^T B(\tau)
          B^*(\tau) d\tau}$
        </div>
        <div class="content">
          <ol>
            <li>
              $A$ симметрична: $A^* = A$.
              <br>

              <div class="derivation">
                \[
                A^* = \paren{\int\limits_0^T B B^* d\tau}^*
                = \int\limits_0^T B B^* d\tau = A.
                \]
              </div>
            </li>

            <li>
              Квадратичная форма с матрицей $A$ знакоположительна:
              \[
              C^*AC \geqslant 0 \qquad \forall C.
              \]
              <div class="derivation">
                \[
                C^*AC \bydef = C^* \int\limits_0^T B B^* d\tau \cdot C
                = \int\limits_0^T C^* B B^* C d\tau
                = \int\limits_0^T \norm{C^* B}^2 d\tau \geqslant 0.
                \]
              </div>
            </li>

            <li>
              Все собственные числа матрицы $A$ вещественны и неотрицательны:
              $\lambda_i \geqslant 0$.

              <div class="derivation">
                <p>
                Из симметричности матрицы $A$ следует, что
                $\lambda_i \in \mathbb{R}$.
                </p>

                <p>
                В канонической форме коэффициенты квадратической формы &mdash;
                собственные числа, поэтому из свойства 2 следует, что
                $\lambda_i \geqslant 0$.
                </p>
              </div>
            </li>

            <li>
              Если матрица $A$ невырождена, то $\lambda_i \gt 0$.
            </li>
          </ol>
        </div>
      </li>

      <li class="question">
        <div class="name">
          Критерии полной управляемости линейной системы (2 штуки)
        </div>
        <div class="content">
          <div class="lemma">
            Матрица $A$ невырождена тогда и только тогда, когда строки матрицы
            $B(t)$ линейно независимы на $[0; T]$.

            <div class="idea">
              Необходимость и достаточность доказываются от противного,
              учитывая тот факт, что
              \[
              C^* A C = \int\limits_0^T \norm{C^* B}^2 d\tau.
              \]
            </div>

            <div class="proof">
              <div class="necessity">
                От противного. Пусть $\det A \neq 0$, но строки матрицы $B(t)$
                линейно зависимы на $[0; T]$, то есть существует $C \neq 0$
                такой, что
                \[
                C^* B(t) \equiv 0, \quad t \in [0; T].
                \]
                Рассмотрим квадратичную форму
                \[
                \begin{aligned}
                C^* A C &= \int\limits_0^T C^* B(\tau) B^*(\tau) C d\tau \\
                &= \int\limits_0^T \norm{C^* B(\tau)}^2 d\tau \\
                &= 0,
                \end{aligned}
                \]
                то есть $C^* A C = 0$. В силу того, что $C \neq 0$, имеем
                $AC = 0$, то есть столбцы матрицы $A$ линейно зависимы, поэтому
                $\det A = 0$, что противоречит исходному предположению.
              </div>

              <div class="sufficiency">
                От противного. Пусть строки матрицы $B(t)$ линейно независимы
                на $[0;T]$, но $\det A = 0$. Тогда существует $C \neq 0$ такой,
                что
                \[
                A C = 0,
                \]
                поэтому
                \[
                \begin{aligned}
                0 &= C^* A C \\
                &= \int\limits_0^T C^* B(\tau) B^*(\tau) C d\tau \\
                &= \int\limits_0^T \norm{C^* B(\tau)}^2 d\tau,
                \end{aligned}
                \]
                откуда следует, что для некоторого ненулевого $C$ выполняется
                тождество
                \[
                C^* B(t) \equiv 0, \qquad t \in [0;T],
                \]
                что вступает в противоречие с предположением линейной
                независимости строк $B(t)$ на $[0; T]$.
              </div>
            </div>
          </div>

          <div class="lemma">
            Строки матрицы $B(t)$ линейно независимы тогда и только тогда,
            когда существуют
            \[
            0 \leqslant t_1 \leqslant t_2 \leqslant \cdots \leqslant t_m
            \leqslant T, \quad m \leqslant n
            \]
            такие, что
            \[
            \rank \left[ B(t_1), B(t_2), \dots, B(t_m) \right] = n.
            \]
          </div>
        </div>
      </li>

      <h2 class="subtitle">
        3. Простейшая задача оптимального управления. Область управляемости и
        область достижимости. Выпуклость множеств
      </h2>

      <li class="question">
        <div class="name">
          Простейшая задача оптимального управления
        </div>
        <div class="content">
          Рассмотрим полностью управляемую линейную систему
          \[
          \dot{x} = P(t) x + Q(t) u + f(t).
          \]
          Для сравнения движений системы и соответствующих программных
          управлений введём <i>критерий оценки качества управления</i> в виде
          функционала
          \[
          J[u(t)] := \int\limits_0^T u^*(\tau) u(\tau) d\tau,
          \]
          который назовём <i>интенсивностью управления</i>.

          <div class="problem">
            Найти программное управление $u(t)$, минимизирующее функционал
            $J[u(t)]$.
          </div>

          <div class="solution">
            В семестве программных управлений
            \[
            u(t) = B^*(t) C + V(t), \quad \text{причём}
            \quad \int\limits_0^T B(\tau) V(\tau) d\tau = 0,
            \]
            будем искать $\widetilde u(t)$ такое, что
            $\min J[u(t)] = J[\widetilde u(t)]$.
            Подставим:
            \[
            \begin{aligned}
            J[u(t)] &= \int\limits_0^T \paren{C^* B(\tau) + V^*(\tau)}
            \paren{B^*(\tau) C + V(\tau)} d\tau \\
            &= \phantom{+} \int\limits_0^T C^*
            \overbrace{B(\tau) B^*(\tau)}^{=A} C d\tau
            + \cancel{\int\limits_0^T C^* B(\tau) V(\tau) d\tau} \\
            &\phantom{=} + \cancel{\int\limits_0^T V^*(\tau) B^*(\tau) d\tau}
            + \int\limits_0^T V^*(\tau) V(\tau) d\tau \\
            &= C^* A C
            + \underbrace{
            \int\limits_0^T V^*(\tau) V(\tau) d\tau
            }_{\displaystyle \geqslant 0}.
            \end{aligned}
            \]

            Первое слагаемое не зависит от управления, а из свойств матрицы $A$
            известно, что для любого $C$
            \[
            C^* A C \geqslant 0,
            \]
            поэтому минимум достигается при $V(t) \equiv 0$, то есть
            \[
            \min J[u(t)] = C^* A C,
            \]
            следовательно, $\widetilde u(t) = B^*(t) C$ &mdash; оптимальное по
            отношению к функционалу $J$ управление.
          </div>
        </div>
      </li>

      <li class="question">
        <div class="name">
          Определение: область управляемости
        </div>
        <div class="content">
          Рассмотрим полностью управляемую линейную однородную систему
          \[
          \dot{x} = P(t) x + Q(t) u, \qquad f(t) \equiv 0.
          \]
          Введём ограничение на интенсивность управления:
          \[
          \int\limits_0^T u^*(\tau) u(\tau) d\tau \leqslant \mu, \quad
          \text{где} \quad \mu \gt 0.
          \]

          <div class="definition">
            <i>Областью управляемости $\mathcal{A}$</i> называют множество
            точек $x_0$, из которых можно попасть в начало координат при помощи
            управления с ограниченной интенсивностью.
          </div>

          <div class="problem">
            Построить область управляемости.
          </div>

          <div class="solution">
            Пусть $x_0 \in \mathcal{A}$. Система полностью управляема, поэтому
            можно построить программное управление для точек $(x_0, \vb{0})$ в
            виде
            \[
            u(t) = B^*(t) C.
            \]

            <div class="remark">
              Если $V(t) \not\equiv 0$, то значение функционала станет больше,
              следовательно, мы не учтём некоторые точки из области
              управляемости.
            </div>

            Так как $x_1 = \vb{0}$, то
            \[
            \eta = \cancel{Y^{-1}(T) \underbrace{x_1}_{=0}} - x_0 -
            \cancel{\int\limits_0^T Y^{-1}(\tau)
            \underbrace{f(\tau)}_{\equiv 0} d\tau} = - x_0.
            \]
            Из теоремы о полной управляемости линейной системы следует
            невырожденность матрицы $A$, поэтому $C = A^{-1} \eta$, а
            управление запишется в виде
            \[
            u(t) = B^*(t) C = B^*(t) A^{-1} \eta = - B^*(t) A^{-1} x_0.
            \]
            Подставим его в уравнение интенсивности:
            \[
            \begin{aligned}
            \int\limits_0^T u^*(\tau) u(\tau) d\tau
            &= \int\limits_0^T x_0^* (A^{-1})^*
            \overbrace{B(\tau) B^*(\tau)}^{=A} A^{-1} x_0 d\tau \\
            &= x_0^* (A^{-1})^* A A^{-1} x_0 \\
            &= x_0^* (A^{-1})^* x_0 \\
            &= x_0^* (A^*)^{-1} x_0 \\
            &= x_0^* A^{-1} x_0 \leqslant \mu.
            \end{aligned}
            \]

            <div class="remark">
              Свойство обратной матрицы: $(A^{-1})^* = (A^*)^{-1}$.
            </div>

            Таким образом, область управляемости $\mathcal{A}$ имеет следующий
            вид:
            \[
            \mathcal{A}: \set{x_0 | x_0^* A^{-1} x_0 \leqslant \mu},
            \]
            то есть $\mathcal{A}$ &mdash; эллипс с центром в начале координат.
          </div>
        </div>
      </li>

      <li class="question">
        <div class="name">
          Определение: область достижимости
        </div>
        <div class="content">
          Рассмотрим полностью управляемую линейную однородную систему
          \[
          \dot{x} = P(t) x + Q(t) u, \qquad f(t) \equiv 0.
          \]
          Введём ограничение на интенсивность управления:
          \[
          \int\limits_0^T u^*(\tau) u(\tau) d\tau \leqslant \mu,
          \quad \text{где} \quad \mu \gt 0.
          \]

          <div class="definition">
            <i>Областью достижимости $\mathcal{D}$</i> называется множество
            точек $x_1$, в которые можно попасть из начала координат при помощи
            программного управления $u(t)$ ограниченной интенсивности.
          </div>

          <div class="problem">
            Построить область достижимости.
          </div>

          <div class="solution">
            Построение проводится аналогично области управляемости.
          </div>

          <div class="remark">
            Задачу о построении программного управления, переводящего систему из
            $x_0 = 0$ в $x_1 \neq 0$ заменой $y = x - x_1$ можно свести к
            задачу о переводе системы из $y_0 = -x_1$ в $y_1 = 0$.
          </div>
        </div>
      </li>

      <li class="question">
        <div class="name">
          Вывод свойства выпуклости множества достижимости
        </div>
        <div class="content">
          Рассмотрим линейную систему
          \[
          \dot{x} = P(t) x + Q(t) u + f(t).
          \]
          Введём ограничение на интенсивность управления:
          \[
          \int\limits_0^T u^*(\tau) u(\tau) d\tau \leqslant \mu,
          \quad \text{где} \quad \mu \gt 0.
          \]

          <div class="theorem">
            Область достижимости $\mathcal{D}$ выпукла:
            \[
            \forall x_1, x_2 \in \mathcal{D}
            \quad \alpha x_2 + (1 - \alpha) x_1 \in \mathcal{D},
            \quad \alpha \in [0; 1].
            \]

            <div class="idea">
              Проверяется подстановкой: элемент области достижимости должен
              быть 1) программным управлением 2) ограниченной интенсивности. Из
              двух элементов надо собрать условия для нового.
            </div>

            <div class="proof">
              <p>
              Так как $x_1, x_2 \in \mathcal{D}$, то существуют программные
              управления $u_1(t), u_2(t)$ ограниченной интенсивности,
              переводящие начало координат в $x_1$ и $x_2$ соответственно.
              </p>

              <p>
              $u_1, u_2$ &mdash; программные управления, поэтому
              \[
              \begin{aligned}
              \int\limits_0^T B(\tau) u_1(\tau) d\tau &= \eta(0, x_1)
              = Y^{-1}(T) x_1 - \int\limits_0^T Y^{-1}(\tau) f(\tau) d\tau \\
              \int\limits_0^T B(\tau) u_2(\tau) d\tau &= \eta(0, x_2)
              = Y^{-1}(T) x_2 - \int\limits_0^T Y^{-1}(\tau) f(\tau) d\tau \\
              \end{aligned}
              \]

              Умножим первое уравнение на $(1 - \alpha)$, второе &mdash; на
              $\alpha$ и сложим их:
              \[
              \begin{aligned}
              \int\limits_0^T B(\tau)
              \underbrace{\left[
              \alpha u_2(\tau) + (1 - \alpha) u_1(\tau)
              \right]}_{\doteq u_3(\tau)} d\tau
              &= (1-\alpha) \left[Y^{-1}(T) x_1
              - \int\limits_0^T Y^{-1}(\tau) f(\tau) d\tau \right] \\
              &\phantom{= (1} + \alpha \phantom{)} \left[Y^{-1}(T) x_2
              - \int\limits_0^T Y^{-1}(\tau) f(\tau) d\tau \right] \\
              \int\limits_0^T B(\tau) u_3(\tau) d\tau
              &= Y^{-1}(T) \left[\alpha x_2 + (1 - \alpha) x_1\right]
              - \int\limits_0^T Y^{-1}(\tau) f(\tau) d\tau.
              \end{aligned}
              \]
              Таким образом, управление $u_3(t)$ переводит систему из начала
              координат в точку $x_3 := \alpha x_2 + (1 - \alpha) x_1$.
              </p>

              <p>
              Проверим интенсивность управления $u_3(t)$ на ограниченность:
              \[
              \begin{aligned}
              \int\limits_0^T u_3^*(\tau) u_3(\tau) d\tau &= \int\limits_0^T
              \left[ \alpha u_2^*(\tau) + (1 - \alpha) u_1^*(\tau) \right]
              \left[ \alpha u_2(\tau) + (1 - \alpha) u_1(\tau) \right] d\tau \\
              &= \alpha^2 \int\limits_0^T u_2^*(\tau) u_2(\tau) d\tau
              + (1 - \alpha)^2 \int\limits_0^T u_1^*(\tau) u_1(\tau) d\tau \\
              &\phantom{=} + \, \alpha(1 - \alpha) \left[
              \int\limits_0^T u_2^*(\tau) u_1(\tau) d\tau
              + \int\limits_0^T u_1^*(\tau) u_2(\tau) d\tau
              \right] \\
              &= \alpha^2
              \underbrace{
              \int\limits_0^T u_2^*(\tau) u_2(\tau) d\tau
              }_{\leqslant\, \mu}
              + (1 - \alpha)^2
              \underbrace{
              \int\limits_0^T u_1^*(\tau) u_1(\tau) d\tau
              }_{\leqslant\, \mu} \\
              &\phantom{=} + \, 2\alpha(1 - \alpha) \int\limits_0^T u_1^*(\tau)
              u_2(\tau) d\tau \\
              &\leqslant \alpha^2 \mu + (1 - \alpha)^2 \mu
              + 2\alpha(1 - \alpha) \int\limits_0^T u_1^*(\tau) u_2(\tau) d\tau.
              \end{aligned}
              \]
              </p>

              <p>
              Введём скалярное произведение:
              \[
              (u_i, u_j) \bydef = \int\limits_0^T u_i^*(\tau) u_j(\tau) d\tau
              \]
              и порождённую им норму
              \[
              \norm{u} \bydef = \sqrt{(u, u)} =
              \sqrt{\int\limits_0^T u_i^*(\tau) u_j(\tau) d\tau}.
              \]

              Из
              <a
                href="https://ru.wikipedia.org/wiki/Неравенство_Коши_—_Буняковского"
                target="_blank">
                неравенства Коши-Буняковского
              </a>
              следует, что
              \[
              \abs{(u_i, u_j)} \leqslant \norm{u_i} \cdot \norm{u_j}
              = \sqrt{\int\limits_0^T u_1^*(\tau) u_1(\tau) d\tau}
              \cdot \sqrt{\int\limits_0^T u_2^*(\tau) u_2(\tau) d\tau}
              \leqslant \sqrt{\mu} \cdot \sqrt{\mu} = \mu,
              \]
              поэтому
              \[
              \begin{aligned}
              \int\limits_0^T u_3^*(\tau) u_3(\tau) d\tau
              &\leqslant \alpha^2 \mu + (1 - \alpha)^2 \mu
              + 2\alpha(1 - \alpha) \int\limits_0^T u_1^*(\tau) u_2(\tau) d\tau
              \\
              &\leqslant \alpha^2 \mu + (1 - \alpha)^2 \mu
              + 2\alpha(1 - \alpha) \mu \\
              &= \mu \paren{\alpha^2 + 2 \alpha (1 - \alpha) + (1 - \alpha)^2}
              \\
              &= \mu \paren{\cancel \alpha + (1 - \cancel \alpha)}^2 \\
              &= \mu.
              \end{aligned}
              \]
              </p>

              <p>
              Значит, $x_3 \in \mathcal{D}$, то есть область достижимости
              выпукла.
              </p>
            </div>
          </div>
        </div>
      </li>

      <h2 class="subtitle">
        4. Достаточное условие полной управляемости
      </h2>

      <li class="question">
        <div class="name">
          Теорема: достаточное условие полной управляемости
        </div>
        <div class="content">
          Рассмотрим линейную систему
          \[
          \dot{x} = P(t) x + Q(t) u + f(t).
          \]

          Составим вспомогательные матрицы:
          \[
          \begin{aligned}
          S_0(t) &\bydef = Q(t) \\
          S_1(t) &= \dot{S}_0(t) - P(t) S_0(t) \\
          &\phantom{=} \dots \\
          S_{n-1}(t) &= \dot{S}_{n-2}(t) - P(t) S_{n-2}(t).
          \end{aligned}
          \]
          Из них составим матрицу $S(t) = \left[ S_0(t), \dots, S_{n-1}(t)
          \right]$.

          <div class="theorem">
            Система полностью управляема на $[0; T]$, если
            \[
            \exists \tau \in [0;T]: \qquad \rank S(\tau) = n.
            \]

            <div class="idea">
              От противного: собираем условие тождественности нулю каждого из
              блоков матрицы $S$, получаем противоречие.
            </div>

            <div class="proof">
              <p>
              От противного: предположим, что
              \[
              \exists \tau \in [0;T]: \qquad \rank S(\tau) = n,
              \]
              но система не является полностью управляемой.
              </p>

              <p>
              Тогда из теоремы о полной управляемости системы следует, что
              $\det A = 0$, что влечёт за собой линейную зависимость строк
              матрицы $B(t)$ (см. свойства матрицы $A$):
              \[
              \exists C \neq \vb{0}: \quad C^* B(t) \equiv 0.
              \]
              По определению $B(t) = Y^{-1}(t) Q(t) = Y^{-1}(t) S_0(t)$, поэтому
              \[
              C^* Y^{-1}(t) S_0(t) \equiv 0.
              \]
              </p>

              <p>
              Рассмотрим теперь уравнение
              \[
              C^* \dot{B}(t) \equiv 0;
              \quad \dot{B}(t) = \dot{Y}^{-1}(t) Q(t) + Y^{-1} \dot{Q}(t).
              \]
              Найдём выражение для $\dot Y^{-1}(t)$: продифференцируем уравнение
              \[
              Y^{-1}(t) Y(t) = E,
              \]
              получим
              \[
              \dot Y^{-1}(t) Y(t) + Y^{-1}(t) \dot Y(t) = 0.
              \]
              Фундаментальная матрица удовлетворяет однородной линейной системе:
              $\dot Y(t) = P(t) Y(t)$, поэтому
              \[
              \dot Y^{-1}(t) Y(t) + Y^{-1}(t) P(t) Y(t) = 0.
              \]
              Домножим справа на $Y^{-1}(t)$:
              \[
              \dot Y^{-1}(t) = - Y^{-1}(t) P(t).
              \]
              Тогда
              \[
              \begin{aligned}
              \dot{B}(t)
              &= \phantom - \dot{Y}^{-1}(t) Q(t) + Y^{-1} \dot{Q}(t) \\
              &= - Y^{-1}(t) P(t) S_0(t) + Y^{-1} \dot S_0(t) \\
              &= \phantom - Y^{-1}(t) \left[\dot S_0(t) - P(t) S_0(t) \right] \\
              &= \phantom - Y^{-1}(t) S_1(t),
              \end{aligned}
              \]
              откуда
              \[
              C^* \dot B(t) = C^* Y^{-1}(t) S_1(t) \equiv 0.
              \]
              </p>

              <p>
              Аналогичными рассуждениями приходим к выводу, что
              \[
              C^* Y^{-1}(t) S_k(t) \equiv 0, \quad k = \overline{0, n-1},
              \]
              поэтому
              \[
              C^* Y^{-1}(t) S(t) \equiv 0.
              \]
              </p>

              <p>
              Рассмотрим последнее тождество в точке $\tau \in [0; T]$:
              \[
              C^* Y^{-1}(\tau) S(\tau) = 0.
              \]
              Введя обозначение
              \[
              \gamma^* := C^* Y^{-1}(\tau) \neq 0,
              \]
              получим
              \[
              \gamma^* S(\tau) = 0, \implies \rank S \lt n,
              \]
              но $\rank S = n$ &mdash; пришли к противоречию.
              </p>
            </div>
          </div>
        </div>
      </li>

      <h2 class="subtitle">
        5. Критерий Калмана полной управляемости
      </h2>

      <li class="question">
        <div class="name">
          Критерий Калмана полной управляемости линейной стационарной системы
        </div>
        <div class="content">
          Рассмотрим линейную стационарную систему
          \[
          \dot{x} = P x + Q u + f(t).
          \]
          Составим вспомогательные матрицы:
          \[
          \begin{aligned}
          S_0(t) &= Q(t) &&= Q \\
          S_1(t) &= \dot{S}_0(t) - P(t) S_0(t) &&= -PQ \\
          &\phantom{=} \dots \\
          S_{n-1}(t) &= \dot{S}_{n-2}(t) - P(t) S_{n-2}(t)
          &&= (-1)^{n-1} P^{n-1} Q.
          \end{aligned}
          \]
          Из них составим <i>матрицу Калмана</i>
          \[
          S = \left[ Q, -PQ, P^2 Q, \dots, (-1)^{n-1} P^{n-1} Q \right]
          \cong \left[ Q, PQ, P^2 Q, \dots, P^{n-1} Q \right].
          \]
          <div class="remark">
            Нам интересен только ранг матрицы $S$, поэтому опускаем знаки.
          </div>

          <div class="theorem">
            (критерий Калмана).
            Линейная стационарная система полностью управляема на $[0; T]$
            тогда и только тогда, когда $\rank S = n$.

            <div class="idea">
              От противного: предполагая, что $\rank S \lt n$, раскладываем
              матрицу $B(t)$ в ряд, пользуясь тем, что фундаментальная матрица
              стационарной системы представляется как $e^{Pt}$, и показываем,
              что в этом случае строки матрицы $B(t)$ ЛНЗ.
            </div>

            <div class="proof">
              <div class="sufficiency">
                Следует из достаточного условия управляемости линейной системы.
              </div>

              <div class="necessity">
                Пусть система полностью управляема. Предположим, что
                $\rank S \lt n$, то есть
                \[
                \exists C \neq 0: \quad C^* S = 0,
                \]
                тогда
                \[
                C^* Q = 0, \quad C^* PQ = 0, \dots, \quad C^* P^{n-1}Q = 0.
                \]

                <p>
                Система полностью управляема, поэтому $\det A \neq 0$,
                следовательно, строки $B(t)$ линейно независимы (см. свойства
                матрицы $A$).
                </p>

                <p>
                В силу стационарности системы $Y(t) = e^{Pt}$, поэтому
                \[
                C^* B(t) = C^* Y^{-1}(t) Q = C^* e^{-Pt} Q
                = \sum_{k=1}^\infty \frac{(-t)^k C^* P^k Q}{k!}.
                \]
                </p>

                <p>
                Рассмотрим матрицу $P^n$ с характеристическим многочленом
                \[
                \lambda^n + \alpha_1 \lambda^{n-1} + \dots + \alpha_n = 0.
                \]
                По
                <a
                  href="https://ru.wikipedia.org/wiki/Теорема_Гамильтона_—_Кэли"
                  target="_blank">
                  теореме Гамильтона-Кэли
                </a>
                \[
                P^n + \alpha_1 P^{n-1} + \dots + \alpha_n = 0,
                \]
                или
                \[
                P^n = - \alpha_1 P^{n-1} - \alpha_2 P^{n-2} - \dots - \alpha_n.
                \]
                </p>

                <p>
                Тогда
                \[
                \begin{aligned}
                C^* P^n Q
                &= C^* \paren{
                - \alpha_1 P^{n-1} - \alpha_2 P^{n-2} - \dots - \alpha_n
                } Q \\
                &= -\alpha_1 \underbrace{C^* P^{n-1} Q}_{=0}
                -\alpha_2 \underbrace{C^* P^{n-2} Q}_{=0} - \dots
                -\alpha_n \underbrace{C^* Q}_{=0} = 0.
                \end{aligned}
                \]
                </p>

                Аналогично $C^* P^k Q = 0$ для любого $k \in \N$,
                поэтому
                \[
                C^* B(t) = \sum_{k=1}^\infty \frac{(-t)^k C^* P^k Q}{k!} = 0,
                \]
                откуда следует линейная зависимость строк $B(t)$ &mdash;
                противоречие.
              </div>
            </div>
          </div>
        </div>
      </li>

      <h2 class="subtitle">
        6. Уточнённый критерий Калмана
      </h2>

      <li class="question">
        <div class="name">
          Уточнённый критерий Калмана полной управляемости линейной
          стационарной системы
        </div>
        <div class="content">
          Рассмотрим линейную стационарную систему
          \[
          \dot{x} = Px + Qu + f(t),
          \]
          построим матрицу Калмана $S = \left[ Q, PQ, P^2 Q, \dots, P^{n-1} Q
          \right]$.

          <div class="lemma">
            Если
            \[
            \rank \left[ Q, PQ, \dots, P^{k-1} Q \right]
            = \rank \left[ Q, PQ, \dots, P^{k-1} Q, P^k Q\right],
            \]
            то дальнейшее добавление блоков $P^{k+i} Q$, где $i \in
            \N$, не увеличит ранга матрицы.

            <div class="idea">
              Пользуясь теоремой Кронекера-Капелли, показываем, что все
              дальнейшие блоки можно представить как линейную комбинацию уже
              имеющихся.
            </div>

            <div class="proof">
              Введём обозначение:
              \[
              P^k Q =: (q_1, \dots, q_r), \quad \text{где} \quad q_k -
              \text{столбцы}.
              \]

              Тогда из теоремы Кронекера-Капелли следует, что
              \[
              q_s = Q \alpha_0^{(s)} + PQ \alpha_1^{(s)} + \cdots + P^{k-1} Q
              \alpha_{k-1}^{(s)}
              \quad \forall s = \overline{1, r}.
              \]

              Так как $P^{k+1} Q = P \cdot P^k Q$, то
              \[
              P q_s = P Q \alpha_0^{(s)} + P^2 Q \alpha_1^{(s)} + \cdots + P^k
              Q \alpha_{k-1}^{(s)}
              \quad \forall s = \overline{1, r},
              \]
              откуда, по теореме Кронекера-Капелли,
              \[
              \begin{aligned}
              \rank \left[ Q, PQ, \dots, P^{k-1} Q \right]
              &= \rank \left[ Q, PQ, \dots, P^{k-1} Q, P^k Q\right] \\
              &= \rank \left[ Q, PQ, \dots, P^k Q, P^{k+1} Q\right].
              \end{aligned}
              \]

              Аналогичные рассуждения можно привести для всех $i \geqslant 2$.
            </div>
          </div>

          <div class="theorem">
            <i>(Уточнённый критерий Калмана)</i>
            Линейная стационарная система полностью управляема тогда и только
            тогда, когда
            \[
            \rank \left[ Q, PQ, \dots, P^{n-l} Q \right] = n, \quad \text{где}
            \quad l = \rank Q.
            \]

            <div class="idea">
              <ul>
                <li>
                  Необходимость: пользуемся предыдущей леммой &mdash;
                  показываем, что рано или поздно сможем получить нужный ранг,
                  иначе противоречие.
                </li>

                <li>
                  Достаточность: если ранг уже равен $n$, то он полный, и
                  дальше нет смысла добавлять блоки.
                </li>
              </ul>
            </div>

            <div class="proof">
              <div class="necessity">
                Пусть система полностью управляема, тогда по критерию Калмана
                \[
                \rank S = n.
                \]

                По условию $\rank Q = l \lt n$. Добавим блок &mdash; рассмотрим
                $\rank [Q, PQ]$. Если
                \[
                \rank Q = \rank [Q, PQ] = l,
                \]
                то по предыдущей лемме дальнейшее добавление блоков его не
                увеличит, поэтому
                \[
                \rank Q = \rank S = l \lt n,
                \]
                что противоречит условию полной управляемости системы. Таким
                образом,
                \[
                \rank Q \lt \rank [Q, PQ] \leqslant n.
                \]

                <div class="remark">
                  При добавлении блоков $P^k Q$ справа количество строк блочной
                  матрицы не увеличивается, значит, её ранг не может
                  превосходить $n$.
                </div>

                <p>
                Ранг увеличился минимум на единицу, поэтому
                \[
                \rank [Q, PQ] = l + m, \quad m \in \N.
                \]
                Если $l + m = n$, то есть $\rank [Q, PQ] = n$, то он полный,
                поэтому добавление блоков его не изменит:
                \[
                \rank [Q, PQ] = \rank S = n,
                \]
                откуда следует полная управляемость.
                </p>

                Предположим, он увеличился на единицу:
                \[
                \rank [Q, PQ] = l + 1 \lt n
                \]
                Проводя аналогичные рассуждения, через $n - l$ шагов
                гарантированно получим, что
                \[
                \rank [Q, PQ, \dots, P^{n-l} Q] = n.
                \]
              </div>

              <div class="sufficiency">
                Пусть $\rank \left[ Q, PQ, \dots, P^{n-l} Q \right] = n$. Он
                <a href="https://ru.wikipedia.org/wiki/Ранг_матрицы"
                  target="_blank">полный</a>,
                поэтому добавление блоков его не изменит:
                \[
                \rank \left[ Q, PQ, \dots, P^{n-l} Q \right] = \rank S = n,
                \]
                значит, по критерию Калмана система полностью управляема.
              </div>
            </div>
          </div>
        </div>
      </li>

      <h2 class="subtitle">
        7. Декомпозиция линейной управляемой системы. Следствие
      </h2>

      <li class="question">
        <div class="name">
          Декомпозиция линейной управляемой системы
        </div>
        <div class="content">
          Рассмотрим линейную стационарную систему
          \[
          \dot{x} = Px + Qu + f(t).
          \]
          Пусть она не полностью управляема, то есть $\rank S = m \lt n$.

          <div class="lemma">
            Линейная оболочка $\Lin S$ &mdash;
            <a
              href="https://ru.wikipedia.org/wiki/Инвариантное_подпространство"
              target="_blank">
              инвариантное подпространство</a>
            относительно умножения на матрицу $P$ слева:
            \[
            \forall l \in \Lin S: \quad P\, l \in \Lin S.
            \]

            <div class="idea">
              Пользуясь теоремой Гамильтона-Кэли, показываем, что $P^n q_i$
              можно представить как линейную комбинацию элементов линейной
              оболочки.
            </div>

            <div class="proof">
              Обозначим столбцы матрицы $Q = (q_1, \dots, q_r)$. Тогда
              \[
              \Lin S
              = \left\lang Q, PQ, \dots, P^{n-1} Q \right\rang
              = \left\lang
              \underbrace{q_1, \dots, q_r}_{Q},
              \underbrace{P q_1, \dots, P q_r}_{P Q},
              \dots,
              \underbrace{P^{n-1} q_1, \dots, P^{n-1} q_r}_{P^{n-1} Q}
              \right\rang.
              \]

              По построению видно, что для всех $k = \overline{0, n-2}$
              \[
              P^k q_i \in \Lin S \implies P^{k+1} q_i \in \Lin S,
              \quad i = \overline{1,r}.
              \]

              Значит, остаётся проверить случай $k = n-1$. Рассмотрим
              \[
              P^{n-1} q_i \in \Lin S, \quad i \in \overline{1, r}.
              \]

              Запишем характеристический полином матрицы $P^n$:
              \[
              \lambda^n + \alpha_1 \lambda^{n-1} + \cdots + \alpha_{n-1}
              \lambda + \alpha_n = 0.
              \]

              Из
              <a href="https://ru.wikipedia.org/wiki/Теорема_Гамильтона_—_Кэли"
                target="_blank">
                теореме Гамильтона-Кэли</a>
              следует, что
              \[
              P^n = -\alpha_1 P^{n-1} - \alpha_2 P^{n-2} - \cdots - \alpha_n E.
              \]

              Домножим справа на $q_i$:
              \[
              P^n q_i = -\alpha_1 P^{n-1} q_i - \alpha_2 P^{n-2} q_i - \cdots
              - \alpha_n q_i.
              \]
              Значит, $P^n q_i$ является линейной комбинацией векторов
              $q_i, P q_i, \dots, P^{n-1} q_i$, откуда
              \[
              P \cdot P^{n-1} q_i = P^n q_i \in \Lin S.
              \]
            </div>
          </div>

          <div class="theorem">
            Если $\rank S = m \lt n$, то существует неособое преобразование
            переменных $x$, приводящее к декомпозиции системы
            \[
            \dot{x} = Px + Qu + f(t)
            \]
            на <i>управляемую</i> и <i>неуправляемую</i> части.

            <div class="idea">
              Дополняем базис линейной оболочки до базиса всего пространства,
              собираем из него матрицу $T$ и показываем, что после
              преобразования $x = T y$ действительно произошла декомпозиция.
            </div>

            <div class="proof">
              <p>
              Рассмотрим линейную оболочку $\Lin S$. В неё входит $m$ линейно
              независимых векторов, обозначим их как $s_1, \dots, s_m$.
              Дополним этот набор до базиса $\mathbb{E}^n$ векторами
              $\widetilde{s}_{m+1}, \dots, \widetilde{s}_n$. Обозначим
              \[
              T := \left[ s_1, \dots, s_m, \widetilde{s}_{m+1}, \dots,
              \widetilde{s}_n \right]
              \]
              и проведём замену переменных $x = Ty$, тогда
              \[
              T \dot{y} = P T y + Q u + f(t),
              \]
              матрица $T$ невырождена, поэтому домножим на $T^{-1}$ слева:
              \[
              \dot{y} = T^{-1} P T y + T^{-1} Q u + T^{-1} f(t).
              \]

              Введя обозначения
              \[
              \widetilde{P} := T^{-1} P T, \quad \widetilde{Q} := T^{-1} Q,
              \quad \widetilde{f}(t) := T^{-1} f(t),
              \]
              перепишем стационарную систему:
              \[
              \dot{y} = \widetilde{P} y + \widetilde{Q} u + \tilde{f}(t).
              \]
              </p>

              <p>
              Выясним структуру матриц $\widetilde{P}$ и $\widetilde{Q}$.
              </p>

              <p>
              Начнём с $\widetilde{P} = T^{-1} P T$. Обозначим её столбцы как
              $\widetilde{P} = \paren{
              \tilde{p}_1, \dots, \tilde{p}_m, \tilde{p}_{m+1}, \dots,
              \tilde{p}_n
              }$.
              </p>

              <p>
              Рассмотрим уравнение $T \widetilde{P} = P T$ по столбцам:
              </p>

              <ul>
                <li>
                  $T \tilde{p}_1 = P s_1$. Так как $s_1 \in \Lin S$, по лемме
                  $P s_1 \in \Lin S$, поэтому $T \tilde{p}_1$ представим в виде
                  линейной комбинации векторов $(s_1, \dots, s_m)$.
                </li>

                <li>
                  Аналогично для $\tilde{p}_2, \dots, \tilde{p}_m$.
                </li>

                <li>
                  Рассмотрим $T \tilde{p}_{m+1} = P \tilde{s}_{m+1}$. Так как
                  $\tilde{s}_{m+1} \not\in \Lin S$ и $P \tilde{s}_{m+1} \not\in
                  \Lin S$, вектор $\tilde{p}_{m+1}$ раскладывается по столбцам
                  $T$.
                </li>

                <li>
                  Аналогично для $\tilde{p}_{m+2}, \dots, \tilde{p}_n$.
                </li>
              </ul>

              <p>
              Значит,
              \[
              \widetilde{P} = \paren{
              \begin{array}{ccc|ccc}
              \tilde{p}_{1,1} & \dots & \tilde{p}_{1,m} & \tilde{p}_{1,m+1}
              & \dots & \tilde{p}_{1,n} \\
              \vdots & \ddots & \vdots & \vdots & \ddots & \vdots \\
              \tilde{p}_{m,1} & \dots & \tilde{p}_{m,m} & \tilde{p}_{m,m+1}
              & \dots & \tilde{p}_{m,n} \\
              \hline
              0 & \dots & 0 & \tilde{p}_{m+1,m+1} & \dots & \tilde{p}_{m+1,n} \\
              \vdots & \ddots & \vdots & \vdots & \ddots & \vdots \\
              0 & \dots & 0 & \tilde{p}_{n,m+1} & \dots & \tilde{p}_{n,n}
              \end{array}
              }
              =
              \paren{
              \begin{array}{cc}
              P_{11} & P_{12} \\
              0_{(n-m) \times (n-m)} & P_{22}
              \end{array}
              }.
              \]
              </p>

              <p>
              Выясним теперь структуру матрицы
              $\widetilde{Q} = \paren{\tilde{q}_1, \dots, \tilde{q}_r}$.
              Рассмотрим уравнение $T \widetilde{Q} = Q$ по столбцам:
              </p>

              <ul>
                <li>
                  $T \tilde{q}_1 = q_1$. Так как $q_1 \in \Lin S$, вектор
                  $\tilde{q}_1$ представим в виде линейной комбинации векторов
                  $(s_1, \dots, s_m)$.
                </li>

                <li>
                  Аналогично для $\tilde{q}_2, \dots, \tilde{q}_r$.
                </li>
              </ul>

              <p>
              Таким образом,
              \[
              \widetilde{Q} = \paren{
              \begin{array}{ccc}
              \tilde{q}_{1,1} & \dots & \tilde{q}_{1, r} \\
              \vdots & \ddots & \vdots \\
              \tilde{q}_{m,1} & \dots & \tilde{q}_{m, r} \\
              0 & \dots & 0 \\
              \vdots & \ddots & \vdots \\
              0 & \dots & 0
              \end{array}
              }
              =
              \paren{
              \begin{array}{c}
              Q_1 \\
              0_{(n-m) \times (n-m)}
              \end{array}
              }.
              \]
              </p>

              <p>
              Обозначив
              \[
              y =: \paren{
              \begin{array}{c}
              y_1 \\
              y_2
              \end{array}
              } \quad
              \tilde{f} =: \paren{
              \begin{array}{c}
              f_1(t) \\
              f_2(t)
              \end{array}
              },
              \]
              систему можно переписать в виде
              \[
              \left\{
              \begin{aligned}
              \dot{y}_1 &= P_{11} y_1 + Q_1 u && + P_{12} y_2 + f_1(t), \\
              \dot{y}_2 &= && \phantom{+} P_{22} y_2 + f_2(t).
              \end{aligned}
              \right.
              \]
              Видно, что в первой системе управление есть, а во второй &mdash;
              нет.
              </p>
            </div>
          </div>

          <div class="corollary">
            Для управляемой подсистемы справедливо равенство
            \[
            \rank [Q_1, P_{11} Q_1, \dots, P_{11}^{m-1} Q_1] = m.
            \]

            <div class="idea">
              Собираем $T$, она невырождена, поэтому $\rank S = \rank T^{-1}S$,
              но у последнего члены после $P_{11}^{m-1} Q_1$ линейно зависимы.
            </div>

            <div class="proof">
              <p>
              Случай $m = n$ тривиален: неуправляемая подсистема отсутствует, и
              равенство следует из критерия Калмана.
              </p>

              <p>
              Пусть $\rank S = m \lt n$, то есть система не полностью
              управляема. Рассмотрим
              \[
              T := \left[ s_1, \dots, s_m, \widetilde{s}_{m+1}, \dots,
              \widetilde{s}_n \right]
              \]
              и найдём структуру матрицы $T^{-1} S$:
              </p>

              <ul>
                <li>
                  $T^{-1} Q =: \widetilde{Q}$;
                </li>

                <li>
                  $T^{-1} PQ = T^{-1} P T \cdot T^{-1} Q =: \widetilde{P}
                  \widetilde{Q}$;
                </li>

                <li>
                  $T^{-1} P^2 Q = T^{-1} P T \cdot T^{-1} P Q
                  = \widetilde{P} \cdot \widetilde{P} \widetilde{Q}
                  = \widetilde{P}^2 \widetilde{Q}$;
                </li>

                <li>
                  Дальше аналогично.
                </li>
              </ul>

              Получается, что
              \[
              T^{-1} S = \paren{
              \begin{array}{ccccc}
              Q_1 & P_{11} Q_1 & P_{11}^2 Q_1 & \dots & P_{11}^{n-1} Q_1 \\
              0 & 0 & 0 & \dots & 0
              \end{array}
              },
              \]
              поэтому
              \[
              \begin{aligned}
              \rank S = \rank T^{-1} S &= \rank \left[
              Q_1, P_{11} Q_1, \dots, P_{11}^{m-1} Q_1,
              \underbrace{
              P_{11}^m Q_1, \dots, P_{11}^{n-1} Q_1
              }_{\text{линейно зависимы}}
              \right] \\
              &= \rank \left[ Q_1, P_{11} Q_1, \dots, P_{11}^{m-1} Q_1 \right]
              \end{aligned}
              \]

              <div class="remark">
                Линейную зависимость можно показать, подставляя по теореме
                Гамильтона-Кэли матрицу $P_{11}^m$ в характеристический
                многочлен и получая линейную комбинацию, а потом по лемме о
                том, что добавление блоков не увеличивает ранг.
              </div>
            </div>
          </div>
        </div>
      </li>

      <h2 class="subtitle">
        8. Критерий Хаутуса полной управляемости 
      </h2>

      <li class="question">
        <div class="name">
          Критерий Хаутуса полной управляемости
        </div>
        <div class="content">
          Рассмотрим линейную стационарную систему
          \[
          \dot{x} = Px + Qu + f(t).
          \]

          <div class="theorem">
            <i>
              (Критерий управляемости Хаутуса).
            </i>
            Система полностью управляема тогда и только тогда, когда
            \[
            \rank(sE - P, Q) = n \quad \forall s \in \mathbb{C}.
            \]

            <div class="idea">
              Обе ветки доказательства доказываются от противного:
              <ul>
                <li>
                  Для необходимости собирается факт, что $\rank S \lt n$
                </li>

                <li>
                  Для достаточности декомпозируем систему на управляемую и
                  неуправляемую подсистемы, причём $\widetilde P$ и
                  $\widetilde Q$ &mdash; соответствующие матрицы после
                  преобразования. Затем доказывается, что
                  $\rank (\lambda E - P, Q) = \rank (\lambda E - \widetilde{P},
                  \widetilde{Q})$, но у последней строки ЛЗ.
                </li>
              </ul>
            </div>

            <div class="proof">
              <div class="remark">
                Если $s$ не является собственным числом матрицы $P$, то
                равенство выполняется, поэтому будем рассматривать только
                случай $s = \lambda$, где $\lambda = \lambda(P)$.
              </div>

              <div class="necessity">
                Если система полностью управляема, то из критерия Калмана
                следует, что
                \[
                \rank S = n.
                \]

                Предположим, что существует собственное число $\lambda_0$
                такое, что
                \[
                \rank \paren{\lambda_0 E - P, Q} \lt n,
                \]
                значит, строки матрицы $\paren{\lambda_0 E - P, Q}$ линейно
                зависимы:
                \[
                \exists C \neq 0: \quad C^* \paren{\lambda_0 E - P, Q} = 0,
                \implies
                \left\{
                \begin{aligned}
                C^* Q &= 0 \\
                C^* P &= \lambda_0 C^*.
                \end{aligned}
                \right.
                \]

                Отсюда следует, что
                \[
                \begin{aligned}
                &C^* \cdot P Q &&= \lambda_0 C^* Q &&= 0 \\
                &C^* \cdot P^2 Q &&= \lambda_0 C^* P Q &&= 0 \\
                & &&\dots \\
                &C^* \cdot P^{n-1} Q &&= \lambda_0 C^* P^{n-2} Q &&= 0,
                \end{aligned}
                \]
                поэтому
                \[
                C^* \left[ Q, PQ, \dots, P^{n-1} Q \right] = 0,
                \]
                значит, строки матрицы Калмана $S$ линейно зависимы:
                $\rank S \lt n$, что противоречит условию.
              </div>

              <div class="sufficiency">
                Пусть $\rank (\lambda E - P, Q) = n$.

                <p>
                Предположим, что система не полностью управляема, то есть
                $\rank S = m \lt n$. Тогда существует несобственное
                преобразование переменных $x = T y$, приводящее к декомпозиции
                системы на управляемую и неуправляемую подсистемы.
                </p>

                <p>
                Обозначим за $\widetilde P$ и $\widetilde Q$ соответствующие
                матрицы системы после преобразования и выясним, чему равен
                $\rank (\lambda E - \widetilde{P}, \widetilde{Q})$:
                \[
                (\lambda E - \widetilde{P}, \widetilde{Q}) =
                (\lambda T^{-1} T - T^{-1} P T, T^{-1} Q) = T^{-1}
                (\lambda T - P T, Q) = T^{-1} \left[(\lambda E - P) T, Q\right].
                \]
                Матрица $T$ невырождена, поэтому $\rank (\lambda E - P, Q)
                = \rank (\lambda E - \widetilde{P}, \widetilde{Q}) = n$. Из
                этого факта можно сделать вывод, что строки матрицы $(\lambda E
                - \widetilde{P}, \widetilde{Q})$ линейно независимы.
                </p>

                Рассмотрим
                \[
                \paren{\lambda E - \widetilde{P}, \widetilde{Q}} = \paren{
                \begin{array}{ccc}
                \lambda E - P_{11} & P_{12} & Q_1 \\
                0 & \lambda E - P_{22} & 0 \\
                \end{array}
                }.
                \]
                Выберем $\lambda$ так, чтобы оно было собственным числом матрицы
                $\lambda E - P_{22}$. В этом случае
                \[
                \rank (\lambda E - P_{22}) \lt n - m,
                \]
                поэтому
                \[
                \rank (\lambda E - P, Q) = \rank (\lambda E - \widetilde{P},
                \widetilde{Q}) \lt n
                \]
                &mdash; противоречие.
              </div>
            </div>
          </div>
        </div>
      </li>

      <h2 class="subtitle">
        9. Матричная норма
      </h2>

      <li class="question">
        <div class="name">
          Определение: векторная норма
        </div>
        <div class="content">
          <div class="definition">
            $\norm{\cdot}$ &mdash; <i>векторная норма</i>, если:
            <ol>
              <li>
                $\norm{x} \geqslant 0; \quad \norm{x} = 0 \iff x = 0$.
              </li>

              <li>
                $\forall \alpha \in \mathbb{C} \quad \norm{\alpha x}
                = \abs{\alpha} \norm{x}$.
              </li>

              <li>
                $\norm{x + y} \leqslant \norm{x} + \norm{y}$.
              </li>
            </ol>
          </div>
        </div>
      </li>

      <li class="question">
        <div class="name">
          Примеры векторной нормы
        </div>
        <div class="content">
          <ul>
            <li>
              Манхэттенская норма:
              \[
              \norm{x}_1 = \sum_i \abs{x_i}
              \]
            </li>

            <li>
              Евклидова норма:
              \[
              \norm{x}_2 = \sqrt{\sum_{i=1}^n \abs{x_i}^2}
              \]
            </li>

            <li>
              Норма Чебышева:
              \[
              \norm{x}_\infty = \max\limits_i \abs{x_i}
              \]
            </li>
          </ul>
        </div>
      </li>

      <li class="question">
        <div class="name">
          Определение: матричная норма
        </div>
        <div class="content">
          <div class="definition">
            $\norm{\cdot}$ &mdash; <i>матричная норма</i>, если:
            <ol>
              <li>
                $\norm{A} \geqslant 0; \quad \norm{A} = 0 \iff A = 0$.
              </li>

              <li>
                $\forall \alpha \in \mathbb{C} \quad \norm{\alpha A}
                = \abs{\alpha} \norm{A}$.
              </li>

              <li>
                $\norm{A + B} \leqslant \norm{A} + \norm{B}$.
              </li>

              <li>
                $\norm{AB} \leqslant \norm{A} \norm{B}$.
              </li>
            </ol>
          </div>
        </div>
      </li>

      <li class="question">
        <div class="name">
          Определение: подчинённая (индуцированная) матричная норма
        </div>
        <div class="content">
          <div class="definition">
            Матричная норма $\norm{A}$ называется <i>подчинённой</i>
            (<i>индуцированной</i>) векторной норме $\norm{x}$, если
            \[
            \norm{A} = \max\limits_{\norm{x} = 1} \norm{A x}.
            \]
          </div>
        </div>
      </li>

      <li class="question">
        <div class="name">
          Определение: согласованная матричная норма
        </div>
        <div class="content">
          <div class="definition">
            Матричная норма $\norm{A}_{ab}$ называется <i>согласованной</i> с
            векторными нормами $\norm{x}_a$ и $\norm{x}_b$, если
            \[
            \norm{A x}_a \leqslant \norm{A}_{ab} \cdot \norm{x}_b
            \]
          </div>
        </div>
      </li>

      <li class="question">
        <div class="name">
          Примеры матричной нормы
        </div>
        <div class="content">
          Порождённые нормы: $\norm{A}_p = \sup\limits_{\norm{x}_p = 1}
          \norm{A x}_p$:
          <ul>
            <li>
              $p = 1$:
              \[
              \norm{x}_1 = \sum_i \abs{x_i}, \qquad
              \norm{A}_1 = \max\limits_j \paren{\sum_i \abs{a_{ij}}}
              \]
            </li>

            <li>
              $p = 2$:
              \[
              \norm{x}_2 = \sqrt{\sum_{i=1}^n \abs{x_i}^2}.
              \]

              Если $A$ &mdash; квадратная, то подчинённая норма называется
              <i>спектральной</i>.

              <div class="proposition">
                $\norm{A}_2 = \sqrt{\max\limits_k \lambda_k}$, где $\lambda_k$
                &mdash; собственые числа матрицы $A^* A$.
              </div>

              <div class="derivation">
                Норма $\norm{\cdot}_2$ &mdash; порождённая, поэтому
                \[
                \norm{A}_2 \bydef = \max\limits_{\norm{x}_2 = 1}
                \paren{\sqrt{x^* A^* A x}}.
                \]
                Возведём в квадрат:
                \[
                \norm{A}_2^2 = \max\limits_{\norm{x}_2 = 1} \paren{x^* A^* A x}.
                \]

                Упорядочим собственные числа матрицы $A^* A$:
                \[
                \lambda_1 \geqslant \lambda_2 \geqslant \dots \geqslant
                \lambda_n.
                \]

                Проведём ортонормированную замену: $x = P y$, тогда
                \[
                \begin{aligned}
                \norm{A}_2^2 &= \max\limits_{\norm{x}_2 = 1}
                \paren{x^* A^* A x} \\
                &= \max\limits_{\norm{y}_2 = 1}
                \paren{y^* \underbrace{P^* A^* A P}_{\text{диагонализация}} y}
                \\
                &= \max\limits_{\norm{y}_2 = 1} \paren{
                \sum_{k=1}^n \lambda_k y_k^2
                }.
                \end{aligned}
                \]

                Так как $\norm{y}_2 = 1$, то
                \[
                \norm{y}_2 \bydef = \sqrt{\sum_{k=1}^n y_k} = 1,
                \implies y_1^2 = 1 - \sum_{k=2}^n y_k^2.
                \]
                Домножив на $\lambda_1$, получим
                \[
                \lambda_1 y_1^2 = \lambda_1 - \sum_{k=2}^n \lambda_1 y_k^2.
                \]

                Тогда
                \[
                \begin{aligned}
                \norm{A}_2^2 &= \max\limits_{\norm{y}_2 = 1}
                \paren{\sum_{k=1}^n \lambda_k y_k^2} \\
                &= \max\limits_{\norm{y}_2 = 1} \paren{
                \lambda_1 y_1^2 + \sum_{k=2}^n \lambda_k y_k^2
                } \\
                &= \max\limits_{\norm{y}_2 = 1}
                \paren{\lambda_1 - \sum_{k=2}^n \lambda_1 y_k^2 + \sum_{k=2}^n
                \lambda_k y_k^2} \\
                &= \max\limits_{\norm{y}_2 = 1}
                \paren{\lambda_1 + \sum_{k=2}^n
                \underbrace{(\lambda_k - \lambda_1)}_{\leqslant 0} y_k^2} \\
                &= \lambda_1.
                \end{aligned}
                \]

                Таким образом, $\norm{A}_2 = \sqrt{\lambda_1}$.
              </div>

              <div class="corollary">
                Если $A = \diag \paren{A_1, \dots, A_m}$ то
                $\norm{A} = \max\limits_k \norm{A_k}$.
              </div>
            </li>

            <li>
              $p = \infty$:
              \[
              \norm{x}_\infty = \max\limits_i \abs{x_i}, \qquad
              \norm{A}_\infty = \max\limits_i \paren{\sum_j \abs{a_{ij}}}
              \]
            </li>
          </ul>

          <div class="example">
            Евклидова норма
            \[
            \norm{A} = \sqrt{\sum_{i=1}^n \sum_{j=1}^m a_{ij}^2}
            \]
            согласована с векторной нормой
            \[
            \norm{x}_2 = \sqrt{\sum_{i=1}^n \abs{x_i}^2}.
            \]
          </div>
        </div>
      </li>

      <h2 class="subtitle">
        10. Матричная экспонента
      </h2>

      <li class="question">
        <div class="name">
          Матричная экспонента
        </div>
        <div class="content">
          Рассмотрим линейную стационарную систему
          \[
          \dot{x} = P x + Q u + f(t).
          \]
          Фундаментальная матрица соответствующей однородной системы может быть
          представлена в виде
          \[
          Y(t) = e^{Pt} \bydef = \sum_{k=0}^\infty \frac{P^k t^k}{k!}.
          \]

          <p>
          Предположим, что $J$ &mdash; жорданова нормальная форма матрицы $P$.
          Тогда
          \[
          J = \diag (J_1, \dots, J_m).
          \]
          Каждую жорданову клетку можно представить в виде
          \[
          J_k = \paren{
          \begin{array}{ccccc}
          \lambda_k & 1 & 0 & \dots & 0 & 0 \\
          0 & \lambda_k & 1 & \dots & 0 & 0 \\
          0 & 0 & \lambda_k & \dots & 0 & 0 \\
          \vdots & \vdots & \vdots & \ddots & \vdots & \vdots \\
          0 & 0 & 0 & \dots & \lambda_k & 1 \\
          0 & 0 & 0 & \dots & 0 & \lambda_k
          \end{array}
          }_{n_k \times n_k}
          =
          \lambda_k E + \paren{
          \begin{array}{ccccc}
          0 & 1 & 0 & \dots & 0 & 0 \\
          0 & 0 & 1 & \dots & 0 & 0 \\
          0 & 0 & 0 & \dots & 0 & 0 \\
          \vdots & \vdots & \vdots & \ddots & \vdots & \vdots \\
          0 & 0 & 0 & \dots & 0 & 1 \\
          0 & 0 & 0 & \dots & 0 & 0
          \end{array}
          }_{n_k \times n_k}
          =
          \lambda_k E + I_k,
          \]
          где $n_k$ &mdash; кратность соответствующего
          собственного числа, а $I_k$ называют матрицей сдвига. Она
          <a href="https://ru.wikipedia.org/wiki/Нильпотентная_матрица"
            target="_blank">
            нильпотентна</a>:
          \[
          I_k^{n_k} = 0,
          \]
          поэтому
          \[
          e^{J_k t} = e^{\lambda_k E t} e^{I_k t}
          = e^{\lambda_k t} \sum_{m=0}^{n_k - 1} \frac{t^m I_k^m}{m!}.
          \]
          </p>
        </div>
      </li>

      <li class="question">
        <div class="name">
          Свойства матричной экспоненты
        </div>
        <div class="content">
          <ol>
            <li>
              Фундаментальная матрица $Y(t) = C e^{Pt}$, нормированная в нуле
              ($Y(0) = E$), называется <i>матрицантом</i>.
            </li>

            <li>
              Если матрицы $A, B$ коммутируют:
              \[
              \left[A, B\right] = AB - BA = 0,
              \]
              то
              \[
              e^{(A + B) t} = e^{A t} e^{B t} = e^{B t} e^{A t}.
              \]
            </li>

            <li>
              ${\displaystyle \det e^{Pt} = e^{t \Sp P}}$, где $\Sp P$ &mdash;
              <a href="https://ru.wikipedia.org/wiki/След_матрицы"
                target="_blank">
                след матрицы</a>.
            </li>

            <li>
              Справедливо неравенство:
              \[
              \norm{e^{Pt}} \leqslant e^{\abs{t} \norm{P}}.
              \]

              <div class="derivation">
                \[
                \norm{e^{Pt}} \bydef
                = \norm{\sum_{k=0}^\infty \frac{P^k t^k}{k!}}
                \leqslant \sum_{k=0}^\infty \frac{1}{k!}
                \paren{\abs{t} \norm{P}}^k
                = e^{\abs{t} \norm{P}}.
                \]
              </div>
            </li>

            <li>
              Если $P = S J S^{-1}$, где $S$ &mdash; невырожденная матрица, то
              \[
              e^{Pt} = S e^{J t} S^{-1}.
              \]
            </li>
          </ol>
        </div>
      </li>

      <h2 class="subtitle">
        11. Оценка нормы матричной экспоненты
      </h2>

      <li class="question">
        <div class="name">
          Лемма об оценке матричной нормы
        </div>
        <div class="content">
          <div class="remark">
            Считаем, что $t \geqslant 0$.
          </div>

          <div class="lemma">
            Рассмотрим жорданову клетку $J$, пусть соответствующее собственное
            число имеет вид $\lambda = \alpha + i \beta$, и кратность $n$,
            тогда
            \[
            \forall \varepsilon \gt 0 \quad \exists C = C(\varepsilon) \gt 0:
            \qquad \norm{e^{J t}} \leqslant C e^{(\alpha + \varepsilon) t}.
            \]

            <div class="idea">
              Жорданова клетка раскладывается в ряд, умножается на
              $e^\varepsilon \cdot e^{-\varepsilon}$, после чего показывается
              ограниченность нужного множителя.
            </div>

            <div class="proof">
              \[
              \norm{e^{J t}} = \abs{e^{\lambda t}} \norm{\sum_{k=0}^{n - 1}
              \frac{t^k I^k}{k!}}
              \leqslant e^{\alpha t} \sum_{k=0}^{n-1} \frac{t^k}{k!} \norm{I}^k
              = e^{\alpha t} e^{\varepsilon t} \cdot e^{-\varepsilon t}
              \sum_{k=0}^{n-1} \frac{t^k}{k!}
              \]

              Множитель ${\displaystyle e^{-\varepsilon t} \sum_{k=0}^{n-1}
              \frac{t^k}{k!}}$ ограничен при $\varepsilon \gt 0$ и
              $t \geqslant 0$, то есть
              \[
              \forall \varepsilon \gt 0 \quad \exists C = C(\varepsilon) \gt 0:
              \qquad e^{-\varepsilon t} \sum_{k=0}^{n-1} \frac{t^k}{k!}
              \leqslant C,
              \]
              поэтому
              \[
              \forall \varepsilon \gt 0 \quad \exists C = C(\varepsilon) \gt 0:
              \qquad \norm{e^{J t}} \leqslant C e^{(\alpha + \varepsilon) t}.
              \]
            </div>
          </div>
        </div>
      </li>

      <li class="question">
        <div class="name">
          Теорема: оценка нормы матричной экспоненты
        </div>
        <div class="content">
          <div class="theorem">
            Обозначим собственные числа матрицы $P$ как
            $\lambda_k = \alpha_k + i \beta_k$. Положим
            \[
            \alpha := \max\limits_{k} \alpha_k,
            \]
            тогда
            \[
            \forall \varepsilon \gt 0
            \quad \exists \gamma = \gamma(\varepsilon) \gt 0:
            \qquad \norm{e^{P t}} \leqslant \gamma e^{(\alpha + \varepsilon) t}.
            \]

            <div class="idea">
              Матрица преобразуется в ЖНФ, после чего используется тот факт, что
              норма диагональной матрицы равна максимуму норм диагональных
              элементов, а дальше идёт оценка этого максимального элемента.
            </div>

            <div class="proof">
              Пусть $S$ &mdash; невырожденная матрица такая, что
              $P = S J S^{-1}$, тогда
              \[
              e^{Pt} = S e^{J t} S^{-1}, \implies
              \norm{e^{Pt}} \leqslant \norm{S} \cdot \norm{e^{J t}} \cdot
              \norm{S^{-1}}.
              \]
              Так как $e^{Jt} = \diag \paren{e^{J_1 t}, \dots, e^{J_m t}}$, то
              \[
              \norm{e^{Jt}} = \max\limits_k \norm{e^{J_k t}}.
              \]

              Из леммы об оценке матричной нормы известно, что для всех
              $k = \overline{1, m}$
              \[
              \forall \varepsilon \gt 0
              \quad \exists C_k = C_k(\varepsilon) \gt 0:
              \qquad \norm{e^{J_k t}}
              \leqslant C_k e^{(\alpha_k + \varepsilon) t}.
              \]
              Положим
              \[
              \alpha := \max\limits_{k} \alpha_k, \quad \text{соответственно}
              \quad C(\varepsilon) := \max\limits_{k} C_k(\varepsilon)
              \quad \forall \varepsilon \gt 0,
              \]
              тогда
              \[
              \forall \varepsilon \gt 0
              \quad \exists C = C(\varepsilon) \gt 0:
              \qquad \norm{e^{Jt}} \leqslant C e^{(\alpha + \varepsilon) t}.
              \]

              Обозначив $\gamma = \norm{S} \cdot \norm{S^{-1}} \cdot C$, получим
              \[
              \forall \varepsilon \gt 0
              \quad \exists \gamma = \gamma(\varepsilon) \gt 0:
              \qquad
              \norm{e^{Pt}} \leqslant \gamma e^{(\alpha + \varepsilon) t}.
              \]
            </div>
          </div>
        </div>
      </li>

      <h2 class="subtitle">
        12. Устойчивость линейных систем. Основные определения
      </h2>

      <!--
        FIXME: добавить определения устойчивости и асимтотической устойчивости
      -->

      <li class="question">
        <div class="name">
          Определение: бесконечно малый высший предел
        </div>
        <div class="content">
          <div class="definition">
            Говорят, что функция $V(t,x)$ <i>допускает бесконечно малый высший
              предел (б.м.в.п.)</i>, если
            <ul>
              <li>
                $V(t,0) \equiv 0$;
              </li>

              <li>
                $\forall \varepsilon \gt 0 \quad \exists \delta \gt 0:
                \quad \forall t \geqslant 0, \; x: \norm{x} \lt \delta
                \qquad \abs{V(t,x)} \lt \varepsilon$.
              </li>
            </ul>
          </div>
        </div>
      </li>

      <li class="question">
        <div class="name">
          Определение: экспоненциальная устойчивость нулевого решения системы
          ОДУ
        </div>
        <div class="content">
          Рассмотрим систему ОДУ
          \[
          \dv{x}{t} = f(t,x).
          \]
          Будем считать, что
          \[
          f(t,x) \in C\set{ (t,x): \; t \geqslant 0, \; \norm{x} \lt H},
          \quad \text{где} \quad H \gt 0,
          \]
          и $f(t,0) \equiv 0$.

          <div class="definition">
            Говорят, что $x = 0$ <i>экспоненциально устойчиво</i>, если
            существует $h \gt 0$ такое, что для любого начального условия
            \[
            (t_0, x_0)
            \in \set{ (t,x): \; t \geqslant 0, \; \norm{x} \lt h \lt H}
            \]
            выполнено
            \[
            \norm{x(t, t_0, x_0)} \leqslant N \norm{x_0} e^{-\alpha (t - t_0)},
            \]
            где $N, \alpha \gt 0$ не зависят от выбора $x(t)$.
          </div>
        </div>
      </li>

      <li class="question">
        <div class="name">
          Теорема Ляпунова об устойчивости
        </div>
        <div class="content">
          Рассмотрим систему (1)
          \[
          \dv{x}{t} = f(t,x)
          \]
          и некоторую окрестность точки $x=0$:
          \[
          Z = \set{ (t,x): \; t \geqslant 0, \; \norm{x} \lt H},
          \quad \text{где} \quad H \gt 0.
          \]

          <div class="theorem">
            Если существует положительно определённая функция
            $V(t,x) \in C^1(Z)$ такая, что
            \[
            \at{\dv{V}{t}}{(1)} = W(t,x),
            \]
            где $W(t,x)$ &mdash; неположительно определённая функция, то нулевое
            решение системы (1) устойчиво по Ляпунову.
          </div>
        </div>
      </li>

      <li class="question">
        <div class="name">
          Теорема Ляпунова об асимптотической устойчивости
        </div>
        <div class="content">
          Рассмотрим систему (1)
          \[
          \dv{x}{t} = f(t,x)
          \]
          и некоторую окрестность точки $x=0$:
          \[
          Z = \set{ (t,x): \; t \geqslant 0, \; \norm{x} \lt H},
          \quad \text{где} \quad H \gt 0.
          \]

          <div class="theorem">
            Если существует положительно определённая функция
            $V(t,x) \in C^1(Z)$, допуская б.м.в.п., а также
            \[
            \at{\dv{V}{t}}{(1)} = W(t,x),
            \]
            где $W(t,x)$ &mdash; отрицательно определённая функция, то нулевое
            решение системы (1) асимптотически устойчиво по Ляпунову.
          </div>
        </div>
      </li>

      <li class="question">
        <div class="name">
          Определение: экспоненциальная устойчивость линейной однородной системы
        </div>
        <div class="content">
          <div class="definition">
            Говорят, что линейная однородная система
            \[
            \dot{x} = P(t) x
            \]
            <i>экспоненциально устойчива</i>, если существуют
            $\alpha_1, \alpha_2, \beta_1, \beta_2 \gt 0$ такие, что для любых
            начальных данных $t_0, x_0$
            \[
            \alpha_1 \norm{x_0} e^{-\beta_1 (t - t_0)}
            \leqslant
            \norm{x(t; t_0, x_0)}
            \leqslant
            \alpha_2 \norm{x_0} e^{-\beta_2 (t - t_0)}
            \qquad \forall t \geqslant t_0.
            \]
          </div>
        </div>
      </li>

      <li class="question">
        <div class="name">
          Теорема об экспоненциальной устойчивости линейной однородной системы
        </div>
        <div class="content">
          Рассмотрим систему (1)
          \[
          \dv{x}{t} = A(t) x,
          \]
          где $A(t) \in C[0;+\infty]$.

          <div class="theorem">
            Если существуют квадратичные формы
            \[
            \begin{aligned}
            V(t,x) &= x^* P(t) x, \\
            W(t,x) &= x^* Q(t) x
            \end{aligned}
            \]
            такие, что
            <ol>
              <li>
                существуют $a_1, a_2, b_1, b_2 \gt 0$ такие, что для всех
                $t \geqslant 0$ и $x \in \R^n$
                \[
                \begin{gathered}
                a_1 \norm{x}^2 \leqslant V(t,x) \leqslant a_2 \norm{x}^2, \\
                b_1 \norm{x}^2 \leqslant W(t,x) \leqslant b_2 \norm{x}^2;
                \end{gathered}
                \]
              </li>

              <li>
                $P(t) \in C^1[0;+\infty]$ и
                \[
                \at{\dv{V}{t}}{(1)} = -W(t,x),
                \]
              </li>
            </ol>
            то система экспоненциально устойчива.
          </div>
        </div>
      </li>

      <li class="question">
        <div class="name">
          Свойства фундаментальной матрицы (асимптотически) устойчивой
          однородной системы
        </div>
        <div class="content">
          Рассмотрим однородную систему
          \[
          \dot{x} = P(t) x
          \]
          с фундаментальной матрицей $Y(t)$.
          <ul>
            <li>
              Если система устойчива, то $Y(t)$ ограничена.
            </li>

            <li>
              Если система асимптотически устойчива, то
              <ol>
                <li>
                  $Y(t)$ ограничена;
                </li>

                <li>
                  ${\displaystyle \norm{Y(t)}
                  \underset{t \to \infty}{\longrightarrow} 0}$.
                </li>
              </ol>
            </li>
          </ul>
        </div>
      </li>

      <h2 class="subtitle">
        13. Устойчивость линейных стационарных систем. Теорема
      </h2>

      <li class="question">
        <div class="name">
          Определение: экспоненциальная устойчивость однородной стационарной
          системы
        </div>
        <div class="content">
          <div class="definition">
            Однородная стационарная система
            \[
            \dot{x} = P x
            \]
            называется <i>экспоненциально устойчивой</i>, если
            \[
            \exists \gamma \geqslant 1, \sigma \gt 0: \quad \norm{x(t, x_0)}
            \leqslant \gamma e^{-\sigma t} \norm{x_0}.
            \]
          </div>

          <div class="remark">
            Для стационарной системы экспоненциальная устойчивость влечёт за
            собой асимптотическую устойчивость.
          </div>
        </div>
      </li>

      <li class="question">
        <div class="name">
          Теорема об экспоненциальной устойчивости линейной стационарной системы
        </div>
        <div class="content">
          <div class="remark">
            Считаем, что $t_0 := 0$.
          </div>

          <div class="theorem">
            Система
            \[
            \dot{x} = P x
            \]
            экспоненциально устойчива тогда и только тогда, когда
            $\Re (\lambda_i(P)) \lt 0$.

            <div class="idea">
              Пользуясь теоремой об оценке нормы матричной экспоненты, прямой
              проверкой доказываются обе ветки доказательства.
            </div>

            <div class="proof">
              <div class="necessity">
                Пусть система экспоненциально устойчива. Рассмотрим собственное
                число матрицы $P$:
                \[
                \lambda_0 = \alpha_0 + i \beta_0.
                \]
                Ему соответствует частное решение системы:
                \[
                x(t, x_0) = e^{\lambda_0 t} x_0,
                \]
                тогда
                \[
                \norm{x(t, x_0)} = \norm{e^{\lambda_0 t} x_0}
                \leqslant \abs{e^{\lambda_0 t}} \norm{x_0}
                = e^{\alpha_0 t} \norm{x_0} \leqslant \gamma e^{-\sigma t}
                \norm{x_0},
                \]
                откуда следует, что $\alpha_0 \leqslant -\sigma$, а
                $\sigma \gt 0$, поэтому
                \[
                \Re (\lambda_0) \lt 0.
                \]
                В силу произвольности $\lambda_0$ подобные рассуждения
                справедливы для всех собственных чисел матрицы $P$.
              </div>

              <div class="sufficiency">
                Пусть все собственные числа матрицы $P$ лежат в левой
                полуплоскости, т.е.
                \[
                \Re (\lambda_i(P)) \lt 0.
                \]
                Выпишем общее решение исходной системы в общем виде:
                \[
                x(t, x_0) = Y(t) Y^{-1}(0) x_0.
                \]
                Будем рассматривать нормированную в нуле фундаментальную
                матрицу, то есть $Y(0) = E$, тогда
                \[
                x(t, x_0) = Y(t) x_0 = e^{Pt} x_0.
                \]
                Оценим норму (используя лемму об оценке нормы матричной
                экспоненты):
                \[
                \forall \varepsilon \gt 0 \quad \exists \gamma \gt 0: \qquad
                \norm{x(t, x_0)} \leqslant \norm{e^{Pt}} \cdot \norm{x_0}
                \leqslant \gamma e^{(\alpha + \varepsilon) t} \norm{x_0},
                \]
                где $\alpha := \max\limits_k \Re(\lambda_k)$. Взяв
                $\varepsilon$ таким образом, чтобы
                $\alpha + \varepsilon \lt 0$, положим
                \[
                \begin{aligned}
                \sigma &:= - (\alpha + \varepsilon) \gt 0, \\
                \gamma &:= \max(1, \gamma(\varepsilon)),
                \end{aligned}
                \]
                тогда
                \[
                \norm{x(t, x_0)} \leqslant \gamma e^{-\sigma t} \norm{x_0}.
                \]
              </div>
            </div>
          </div>
        </div>
      </li>

      <h2 class="subtitle">
        14. Управляемость устойчивых линейных стационарных систем. Грамиан
        управляемости
      </h2>

      <li class="question">
        <div class="name">
          Определение: грамиан управляемости
        </div>
        <div class="content">
          Рассмотрим стационарную систему
          \[
          \dot{x} = P x + Q u + f(t).
          \]
          Пусть она асимптотически устойчива, тогда
          <ul>
            <li>
              $Y(t)$ ограничена;
            </li>

            <li>
              $\norm{Y(t)} \underset{t \to \infty}{\longrightarrow} 0$.
            </li>
          </ul>

          Оценим норму фундаментальной матрицы:
          \[
          \norm{x(t, x_0)} \leqslant \norm{Y(t)} \cdot \norm{x_0}
          \leqslant \gamma e^{-\sigma t} \norm{x_0},
          \]
          откуда
          \[
          \norm{Y(t)} \leqslant \gamma e^{-\sigma t}.
          \]

          <div class="definition">
            Матрица
            \[
            U = \int\limits_0^\infty Y(\tau) Q Q^* Y^*(\tau) d\tau
            \]
            называется <i>грамианом управляемости</i>.
          </div>

          <div class="remark">
            Грамиан управляемости существует только для асимптотически
            устойчивых стационарных систем.
          </div>

          <div class="proposition">
            Грамиан управляемости сходится.
          </div>

          <div class="derivation">
            \[
            \begin{aligned}
            \norm{U}
            &\leqslant \int\limits_0^\infty
            \norm{Y(\tau)} \norm{Q} \norm{Q^*} \norm{Y^*(\tau)} d\tau \\
            &\leqslant \int\limits_0^\infty
            \underbrace{\gamma^2 \norm{Q} \norm{Q^*}}_{=C}
            e^{-2 \sigma \tau} d\tau \\
            &= C \int\limits_0^\infty e^{-2 \sigma \tau} d\tau \\
            &= \left.
            \frac{c e^{-2\sigma t}}{-2\sigma}
            \right|_0^{\cancel \infty} \\
            &= \frac{c}{2\sigma}.
            \end{aligned}
            \]
            Удалось ограничить $U$, следовательно, он сходится.
          </div>
        </div>
      </li>

      <li class="question">
        <div class="name">
          Свойства грамиана управляемости
        </div>
        <div class="content">
          Рассмотрим
          \[
          U = \int\limits_0^\infty Y(\tau) Q Q^* Y^*(\tau) d\tau
          \]

          Свойства:
          <ol>
            <li>
              $U = U^*$;
            </li>

            <li>
              $C^* U C \geqslant 0$;
            </li>

            <li>
              $\lambda_j(U) \geqslant 0$;
            </li>

            <li>
              Если $\det U \neq 0$, то $C^* U C \gt 0$, то есть
              $\lambda_j(U) \gt 0$.
            </li>
          </ol>
        </div>
      </li>

      <li class="question">
        <div class="name">
          Теорема о полной управляемости асимптотически устойчивой линейной
          стационарной системы
        </div>
        <div class="content">
          Рассмотрим асимптотически устойчивую систему
          \[
          \dot{x} = P x + Q u + f(t)
          \]
          с грамианом управляемости
          \[
          U = \int\limits_0^\infty Y(\tau) Q Q^* Y^*(\tau) d\tau.
          \]

          <div class="theorem">
            Система полностью управляема на $[0; T]$ тогда и только тогда,
            когда $\det U \neq 0$.

            <div class="idea">
              Доказывается от противного, пользуясь тем фактом, что
              \[
              C^* U C = \int\limits_0^\infty \norm{C^* Y(t) Q}^2 d\tau.
              \]
            </div>

            <div class="proof">
              <div class="necessity">
                <p>
                От противного: пусть система полностью управляема на $[0; T]$,
                но $\det U = 0$. Тогда $\rank U \lt n$, откуда следует линейная
                зависимость столбцов $U$:
                \[
                \exists C \neq 0: \quad U C = 0, \implies C^* U C
                = \int\limits_0^\infty \norm{C^* Y(\tau) Q}^2 d\tau = 0.
                \]
                Значит, $C^* Y(t) Q \equiv 0$ на $[0; T]$. В силу
                стационарности системы $Y(t) = e^{Pt}$, поэтому $C^* P^k Q$ для
                всех $k \geqslant 0$.
                </p>

                <p>
                Но в этом случае следует, что $C^* \left[ Q, PQ, \dots,
                P^{n-1}Q \right] = 0$, то есть $\rank S \lt n$ &mdash;
                противоречие.
                </p>
              </div>

              <div class="sufficiency">
                От противного: пусть $\det U \neq 0$, но система не полностью
                управляема. Тогда $\rank S \lt 0$, откуда следует линейная
                зависимость строк $S$:
                \[
                \exists C \neq 0: \quad C^* Q = 0, C^* P^{n-1}Q = 0.
                \]
                Из теоремы Гамильтона-Кэли следует, что $C^* P^k Q = 0$ для
                всех $k \geqslant 0$, поэтому
                \[
                C^* U C
                = \int\limits_0^\infty C^* Y(\tau) Q Q^* Y^*(\tau) C d\tau.
                = \int\limits_0^\infty \norm{C^* Y(t) Q}^2 d\tau = 0,
                \]
                что противоречит условию $\det U \neq 0$.
              </div>
            </div>
          </div>
        </div>
      </li>

      <li class="question">
        <div class="name">
          Алгоритм нахождения грамиана управляемости
        </div>
        <div class="content">
          Рассмотрим асимптотически устойчивую систему
          \[
          \dot{x} = P x + Q u + f(t)
          \]
          с грамианом управляемости
          \[
          U = \int\limits_0^\infty Y(\tau) Q Q^* Y^*(\tau) d\tau.
          \]

          <div class="lemma">
            Грамиан управляемости удовлетворяет матричному уравнению Ляпунова:
            \[
            UP^* + PU + Q Q^* = 0.
            \]

            <div class="idea">
              Проверяется подстановкой.
            </div>

            <div class="proof">
              Проверим непосредственной подстановкой:
              \[
              \begin{aligned}
              0 &= \paren{
              \int\limits_0^\infty Y(\tau) Q Q^* Y^*(\tau) d\tau
              } P^* + P \paren{
              \int\limits_0^\infty Y(\tau) Q Q^* Y^*(\tau) d\tau
              }
              + Q Q^* \\
              &= 
              \int\limits_0^\infty P e^{P \tau} Q Q^* e^{P^* \tau} d\tau
              +
              \int\limits_0^\infty e^{P \tau} Q Q^* e^{P^* \tau} P^* d\tau
              + Q Q^* \\
              &=
              \int\limits_0^\infty \dv{}{\tau} \paren{
              e^{P \tau} Q Q^* e^{P^* \tau}
              } d\tau + Q Q^* \\
              &= \left.e^{P \tau} Q Q^* e^{P^* \tau} \right|_0^{\cancel\infty}
              + Q Q^* \\
              &= - Q Q^* + Q Q^* \\
              &= 0.
              \end{aligned}
              \]
            </div>
          </div>
        </div>
      </li>

      <li class="question">
        <div class="name">
          Зачем нужен грамиан управляемости?
        </div>
        <div class="content">
          Грамиан управляемости позволяет проверить асимптотически устойчивую
          стационарную систему
          \[
          \dot{x} = P x + Q u + f(t)
          \]
          на полную управляемость без вычисления фундаментальной матрицы.
        </div>
      </li>

      <h2 class="subtitle">
        15. Общая граничная задача. Лемма. Критерий разрешимости ОГЗ
      </h2>

      <li class="question">
        <div class="name">
          Постановка общей граничной задачи
        </div>
        <div class="content">
          Обобщаем построение программного управления.

          <p>
          Расмотрим систему
          \[
          \dot{x} = P(t) x + Q(t) u + f(t),
          \]
          пусть $P(t), Q(t), f(t) \in C([0;T])$.
          </p>

          <p>
          Пусть отрезок $[0; T]$ разбит точками $0 \lt t_1 \lt \dots \lt t_m
          \leqslant T$ на $m$ частей, и пусть заданы $m$ постоянных матриц
          $G_1, \dots G_m$ размерности $N \times n$.
          </p>

          <div class="definition">
            Уравнение, связывающее промежуточные состояния системы
            \[
            \sum_{k=1}^m G_k x(t_k) = h
            \]
            называется <i>общим граничным условием</i>.
          </div>
        </div>
      </li>

      <li class="question">
        <div class="name">
          Лемма о представлении семейства допустимых управлений для ОГЗ
        </div>
        <div class="content">
          Расмотрим систему
          \[
          \dot{x} = P(t) x + Q(t) u + f(t)
          \]
          с заданным общим граничным условием
          \[
          \sum_{k=1}^m G_k x(t_k) = h.
          \]

          Выпишем общее решение задачи Коши:
          \[
          x(t) = Y(t) \paren{x_0 + \int\limits_0^t Y^{-1}(\tau)
          \left[ Q(\tau) u(\tau) + f(\tau) \right] d\tau};
          \]
          подставим выражения
          \[
          \begin{aligned}
          x(t_k) &= Y(t_k) \paren{x_0 + \int\limits_0^{t_k} Y^{-1}(\tau)
          \left[ Q(\tau) u(\tau) + f(\tau) \right] d\tau} \\
          &= Y(t_k) \paren{
          x_0 + \int\limits_0^{t_k} B(\tau) u(\tau) d\tau
          + \int\limits_0^{t_k} Y^{-1}(\tau) f(\tau) d\tau
          }
          \end{aligned}
          \]
          в общее граничное условие:
          \[
          \sum_{k=1}^m G_k Y(t_k) \paren{
          x_0 + \int\limits_0^{t_k} B(\tau) u(\tau) d\tau
          + \int\limits_0^{t_k} Y^{-1}(\tau) f(\tau) d\tau
          } = h.
          \]

          Перенесём налево все слагаемые, содержащие управление, а направо
          &mdash; не содержащие:
          \[
          \sum_{k=1}^m G_k Y(t_k)
          \int\limits_0^{t_k} B(\tau) u(\tau) d\tau
          = h
          - \sum_{k=1}^m G_k Y(t_k) x_0
          - \sum_{k=1}^m G_k Y(t_k)
          \int\limits_0^{t_k} Y^{-1}(\tau) f(\tau) d\tau
          \]

          К сожалению, пределы интегрирования не совпадают. Введём функцию
          \[
          \varphi_k(t) =
          \begin{cases}
          1, & t \in [0; t_k], \\
          0, & t \in (t_k; T],
          \end{cases}
          \]
          на которую домножим соответствующие подынтегральные выражения.
          Тогда можно будет перейти к общему пределу интегрирования:
          \[
          \begin{aligned}
          \sum_{k=1}^m G_k Y(t_k)
          \int\limits_0^{t_k} \varphi_k(\tau) B(\tau) u(\tau) d\tau
          &= h
          - \sum_{k=1}^m G_k Y(t_k) x_0
          - \sum_{k=1}^m G_k Y(t_k)
          \int\limits_0^{t_k} \varphi_k(\tau) Y^{-1}(\tau) f(\tau) d\tau \\
          \int\limits_0^T \sum_{k=1}^m G_k Y(t_k)
          \varphi_k(\tau) B(\tau) u(\tau) d\tau
          &= h
          - \sum_{k=1}^m G_k Y(t_k) x_0
          - \int\limits_0^T \sum_{k=1}^m G_k Y(t_k)
          \varphi_k(\tau) Y^{-1}(\tau) f(\tau) d\tau \\
          \end{aligned}
          \]
          
          Введя обозначения
          \[
          \begin{aligned}
          B_1(t) &:= \sum_{k=1}^m G_k Y(t_k)
          \varphi_k(t) B(t) \\
          \eta &:= h
          - \sum_{k=1}^m G_k Y(t_k) x_0
          - \int\limits_0^T \sum_{k=1}^m G_k Y(t_k)
          \varphi_k(\tau) Y^{-1}(\tau) f(\tau) d\tau,
          \end{aligned}
          \]
          запишем интегральное уравнение для построения программных управлений:
          \[
          \int\limits_0^T B_1(\tau) u(\tau) d\tau = \eta.
          \]

          <div class="lemma">
            Если существует допустимое управление, решающее ОГЗ, то оно
            может быть представлено в виде
            \[
            u(t) = B_1^*(t) C + V(t),
            \]
            причём выполняется условие ортогональности:
            \[
            \int\limits_0^T B_1(\tau) V(\tau) d\tau = 0.
            \]

            <div class="idea">
              Подставим $u(t)$ в уравнение ортогональности, докажем
              совместность системы от противного
              ($\rank A \lt \rank (A, \eta)$), воспользовавшись теоремой
              Фредгольма:
              \[
              A x = b \text{ совместна} \iff \exists \gamma \neq 0:
              \gamma^* a = 0, \; \text{ но } \; \gamma^* b \neq 0.
              \]
            </div>

            <div class="proof">
              Пусть существует допустимое управление $u(t) \in U$. Тогда
              утверждение леммы справедливо, если
              \[
              \int\limits_0^T B_1(\tau) \left[u(\tau) - B_1^*(\tau) C \right]
              d\tau = 0.
              \]
              Перепишем это равенство в виде
              \[
              \int\limits_0^T B_1(\tau) u(\tau) d\tau
              = \int\limits_0^T B_1(\tau) B_1^*(\tau) d\tau \cdot C;
              \]
              рассмотрим его как СЛАУ относительно неизвестного вектора $C$:
              \[
              AC = \eta,
              \]
              где
              \[
              A := \int\limits_0^T B_1(\tau) B_1^*(\tau) d\tau,
              \quad \eta := \int\limits_0^T B_1(\tau) u(\tau) d\tau.
              \]

              <p>
              Из
              <a
                href="https://ru.wikipedia.org/wiki/Теорема_Кронекера_—_Капелли"
                target="_blank">
                теоремы Кронекера-Капелли
              </a> известно, что система совместна тогда и только тогда, когда
              $\rank A = \rank (A, \eta)$.
              </p>

              <p>
              Предположим, что система несовместна, то есть $\rank A \lt \rank
              (A, \eta)$. Тогда по теореме Фредгольма найдётся вектор
              $\gamma \neq 0$ такой, что
              \[
              \gamma^* A = 0, \quad \gamma^* \eta \neq 0.
              \]
              Отсюда следует, что
              \[
              \begin{aligned}
              0 &= \gamma^* A \gamma \\
              &= \gamma^* \int\limits_0^T B_1(\tau) B_1^*(\tau) d\tau \cdot
              \gamma \\
              &= \int\limits_0^T \gamma^* B_1(\tau) B_1^*(\tau) \gamma d\tau \\
              &= \int\limits_0^T \norm{\gamma^* B_1(\tau)}^2 d\tau = 0,
              \end{aligned}
              \]
              то есть $\gamma^* B_1(t) \equiv 0$. Но тогда
              \[
              \gamma^* \eta = \gamma^* \int\limits_0^T B_1(\tau) u(\tau) d\tau
              = \int\limits_0^T \overbrace{\gamma^* B_1(\tau)}^{\equiv 0} u(\tau)
              d\tau = 0,
              \]
              что противоречит выбору $\gamma$. Значит, $\rank A = \rank
              (A,\eta)$, то есть система совместна.
              </p>

              <p>
              Решая эту систему, находим вектор $C$, при котором разность
              $u(t) - B_1^*(t) C$ удовлетворяет условию
              \[
              \int\limits_0^T B_1(\tau)
              \left[u(\tau) - B_1^*(\tau) C \right]
              d\tau = 0.
              \]
              Введя обозначение $V(t) := u(t) - B_1^*(t) C$, получаем, что
              \[
              u(t) = B_1^*(t) C + V(t).
              \]
              </p>
            </div>
          </div>
        </div>
      </li>

      <li class="question">
        <div class="name">
          Критерий разрешимости ОГЗ
        </div>
        <div class="content">
          <div class="theorem">
            ОГЗ разрешима тогда и только тогда, когда
            $\rank A = \rank (A, \eta)$.

            <div class="idea">
              <!-- FIXME: расписать -->
              <span class="todo"></span>
            </div>

            <div class="proof">
              <!-- FIXME: расписать -->
              <span class="todo"></span>
            </div>
          </div>

          <div class="theorem">
            ОГЗ разрешима для любого $\eta$ тогда и только тогда, когда
            $\rank A = n$.

            <div class="idea">
              <!-- FIXME: расписать -->
              <span class="todo"></span>
            </div>

            <div class="proof">
              <!-- FIXME: расписать -->
              <span class="todo"></span>
            </div>
          </div>
        </div>
      </li>

      <h2 class="subtitle">
        16. Построение программных управлений в линейных разностных системах.
        Лемма о представлении семейства допустимых управлений
      </h2>

      <li class="question">
        <div class="name">
          Определение: линейная разностная система
        </div>
        <div class="content">
          <div class="definition">
            <i>Линейная разностная система:</i>
            \[
            x(k+1) = P(k) x(k) + Q(k) u(k) + f(k), \quad k \in \Z.
            \]
          </div>
        </div>
      </li>

      <li class="question">
        <div class="name">
          Фундаментальная матрица линейной разностной системы
        </div>
        <div class="content">
          Рассмотрим линейную разностную систему
          \[
          x(k+1) = P(k) x(k) + Q(k) u(k) + f(k), \quad k \in \Z.
          \]

          <div class="definition">
            <i>Фундаментальная матрица, нормированная в $k_0$</i> &mdash;
            матрица $Y(k,k_0)$ такая, что
            \[
            \begin{aligned}
            Y(k_0, k_0) &= E \\
            Y(k, k_0) &= \sum_{j=k_0}^{k-1} P(j), \quad k \gt k_0.
            \end{aligned}
            \]
          </div>
        </div>
      </li>

      <li class="question">
        <div class="name">
          Определение: общее решение в форме Коши для линейной однородной
          разностной системы
        </div>
        <div class="content">
          <!-- FIXME: найти информацию про случай неоднородной системы -->
          Рассмотрим линейную однородную разностную систему
          \[
          x(k+1) = P(k) x(k), \quad k \in \Z;
          \]
          пусть $Y(k, k_0)$ &mdash; фундаментальная матрица, нормированная
          в $k_0$.
          <div class="definition">
            <i>Общее решение в форме Коши:</i>
            \[
            x(k, k_0, x_0) = Y(k, k_0) x_0.
            \]
          </div>
        </div>
      </li>

      <li class="question">
        <div class="name">
          Построение программного управления для линейной разностной системы
        </div>
        <div class="content">
          <div class="problem">
            Пусть $x(0) = x_0$ и $x(m) = x_1$ &mdash; начальное и конечное
            состояния системы. Требуется найти допустимое управление
            $u(0), \dots, u(m-1)$ такое, чтобы решение разностной системы
            \[
            x(k+1) = P(k) x(k) + Q(k) u(k) + f(k), \quad k \in \Z
            \]
            попадало из $x_0$ в $x_1$ за $m$ шагов.

            <div class="solution">
              Построим систему уравнений, которой должно удовлетворять
              программное управление $u(0), \dots, u(m-1)$:
              \[
              \begin{aligned}
              x(1) &= P(0) x(0) + Q(0) u(0) + f(0), \\
              x(2) &= P(1) x(1) + Q(1) u(1) + f(1), \\
              &\dots \\
              x(m) &= P(m-1) x(m-1) + Q(m-1) u(m-1) + f(m-1).
              \end{aligned}
              \]

              Рекурсивно подставляя значение $x$ с предыдущего шага, приходим к
              равенству:
              \[
              \begin{aligned}
              x_1
              &= {\color{blue} P(m-1) \cdot \ldots \cdot P(1) Q(0) u(0)} \\
              &+ {\color{blue} P(m-1) \cdot \ldots \cdot P(2) Q(1) u(1)} \\
              &+ {\color{blue} \dots} \\
              &+ {\color{blue} P(m-1) Q(m-2) u(m-2)} \\
              &+ {\color{blue} Q(m-1) u(m-1)} \\
              &+ {\color{red} P(m-1) \cdot \ldots \cdot P(1) P(0) x_0} \\
              &+ {\color{red} P(m-1) \cdot \ldots \cdot P(1) f(0)} \\
              &+ {\color{red} \dots} \\
              &+ {\color{red} P(m-1) f(m-2)} \\
              &+ {\color{red} f(m-1)}.
              \end{aligned}
              \]
              Слагаемые, выделенные синим, содержат управление, а выделенные
              красным нет. Введя обозначения
              \[
              \begin{aligned}
              A_0 &:= P(m-1) \cdot \ldots \cdot P(1) Q(0), \\
              A_1 &:= P(m-1) \cdot \ldots \cdot P(2) Q(1), \\
              &\dots \\
              A_{m-2} &:= P(m-1) Q(m-2), \\
              A_{m-1} &:= Q(m-1), \\
              \eta &:= x_1 - \Big[
              \phantom{+} P(m-1) \cdot \ldots \cdot P(1) P(0) x_0 \\
              &\phantom{:= x_1 - \Big[} + P(m-1) \cdot \ldots \cdot P(1) f(0) \\
              &\phantom{:= x_1 - \Big[} + \dots \\
              &\phantom{:= x_1 - \Big[} + P(m-1) f(m-2) \\
              &\phantom{:= x_1 - \Big[} + f(m-1) \Big],
              \end{aligned}
              \]
              уравнение перепишется в виде
              \[
              A_0 u(0) + A_1 u(1) + \dots + A_{m-1} u(m-1) = \eta,
              \]
              или, в векторной форме:
              \[
              A u = \eta,
              \]
              где
              \[
              \begin{aligned}
              A &:=
              \begin{pmatrix}
              A_0 & A_1 & \dots & A_{m-1}
              \end{pmatrix}, \\
              u &:=
              \begin{pmatrix}
              u(0) \\
              u(1) \\
              \vdots \\
              u(m-1)
              \end{pmatrix}.
              \end{aligned}
              \]
            </div>
          </div>
        </div>
      </li>

      <li class="question">
        <div class="name">
          Лемма о представлении семейства допустимых управлений линейной
          разностной системы
        </div>
        <div class="content">
          Рассмотрим линейную разностную систему
          \[
          x(k+1) = P(k) x(k) + Q(k) u(k) + f(k), \quad k \in \Z.
          \]
          Введём обозначения:
          \[
          A_k := P(m-1) \cdot \ldots \cdot P(k+1) Q(k),
          \quad k = \overline{0,m-1}.
          \]

          <div class="lemma">
            Всякое допустимое управление $u(0), \dots, u(m-1)$ разностной
            системы может быть представлено в виде
            \[
            u(k) = A_k^* C + V_k, \quad k = \overline{0, m-1},
            \]
            причём выполняется условие ортогональности
            \[
            \sum_{k=0}^{m-1} A_k V_k = 0.
            \]

            <div class="idea">
              <!-- FIXME: расписать -->
              <span class="todo"></span>
            </div>

            <div class="proof">
              <!-- FIXME: расписать -->
              <span class="todo"></span>
            </div>
          </div>
        </div>
      </li>

      <h2 class="subtitle">
        17. Управляемость пары точек и полная управляемость линейных
        разностных систем
      </h2>

      <li class="question">
        <div class="name">
          Определение: управляемость пары точек линейной разностной системы
        </div>
        <div class="content">
          Рассмотрим линейную разностную систему
          \[
          x(k+1) = P(k) x(k) + Q(k) u(k) + f(k), \quad k \in \Z.
          \]

          <div class="definition">
            Пара точек $(x_0, x_1)$ называется <i>управляемой на $[0;m]$</i>,
            если существует допустимое управление $u(0), \dots, u(m-1)$,
            при котором решение системы удовлетворяет условиям $x(0) = x_0, \;
            x(m) = x_1$.
          </div>
        </div>
      </li>

      <li class="question">
        <div class="name">
          Определение: полная управляемость линейной разностной системы
        </div>
        <div class="content">
          <div class="definition">
            Линейная разностная система
            \[
            x(k+1) = P(k) x(k) + Q(k) u(k) + f(k), \quad k \in \Z,
            \]
            называется <i>полностью управляемой на $[0;m]$</i>, если любая пара
            точек $(x_0, x_1)$ управляема на этом интервале.
          </div>
        </div>
      </li>

      <li class="question">
        <div class="name">
          Критерий управляемости пары точек линейной разностной системы
        </div>
        <div class="content">
          Рассмотрим линейную разностную систему
          \[
          x(k+1) = P(k) x(k) + Q(k) u(k) + f(k), \quad k \in \Z.
          \]

          <div class="lemma">
            Пара точек $(x_0, x_1)$ управляема на $[0; m]$ тогда и только тогда,
            когда
            \[
            \rank A = \rank (A, \eta),
            \]
            где
            \[
            \begin{aligned}
            A &:=
            \begin{pmatrix}
            A_1 & A_2 & \dots & A_{m-1}
            \end{pmatrix}, \\
            A_k &:= P(m-1) \cdot \ldots \cdot P(k+1) Q(k), \\
            \eta &:= x_1 - \Big[
            \phantom{+} P(m-1) \cdot \ldots \cdot P(1) P(0) x_0 \\
            &\phantom{:= x_1 - \Big[} + P(m-1) \cdot \ldots \cdot P(1) f(0) \\
            &\phantom{:= x_1 - \Big[} + \dots \\
            &\phantom{:= x_1 - \Big[} + P(m-1) f(m-2) \\
            &\phantom{:= x_1 - \Big[} + f(m-1) \Big].
            \end{aligned}
            \]

            <div class="idea">
              <!-- FIXME: расписать -->
              <span class="todo"></span>
            </div>

            <div class="proof">
              <!-- FIXME: расписать -->
              <span class="todo"></span>
            </div>
          </div>
        </div>
      </li>

      <li class="question">
        <div class="name">
          Критерий полной управляемости линейной разностной системы
        </div>
        <div class="content">
          Рассмотрим линейную разностную систему
          \[
          x(k+1) = P(k) x(k) + Q(k) u(k) + f(k), \quad k \in \Z.
          \]

          <div class="lemma">
            Система полностью управляема на $[0; m]$ тогда и только тогда,
            когда
            \[
            \rank A = n,
            \]
            где
            \[
            \begin{aligned}
            A &:=
            \begin{pmatrix}
            A_1 & A_2 & \dots & A_{m-1}
            \end{pmatrix}, \\
            A_k &:= P(m-1) \cdot \ldots \cdot P(k+1) Q(k).
            \end{aligned}
            \]

            <div class="idea">
              <!-- FIXME: расписать -->
              <span class="todo"></span>
            </div>

            <div class="proof">
              <!-- FIXME: расписать -->
              <span class="todo"></span>
            </div>
          </div>
        </div>
      </li>

      <h2 class="subtitle">
        18. Управляемость стационарных разностных систем. Критерий Хаутуса
      </h2>

      <li class="question">
        <div class="name">
          Критерий полной управляемости линейной стационарной разностной системы
        </div>
        <div class="content">
          Рассмотрим линейную стационарную разностную систему
          \[
          x(k+1) = P x(k) + Q u(k) + f(k), \quad k \in \Z.
          \]

          <div class="theorem">
            <i>(Критерий полной управляемости).</i>

            Разностная стационарная система полностью управляема на $[0; m]$
            тогда и только тогда, когда
            \[
            \rank \left[ Q, PQ, \dots, P^{m-1}Q \right] = n.
            \]

            <div class="idea">
              <!-- FIXME: расписать -->
              <span class="todo"></span>
            </div>

            <div class="proof">
              <!-- FIXME: расписать -->
              <span class="todo"></span>
            </div>
          </div>

          <div class="theorem">
            <i>(Уточнённый критерий полной управляемости).</i>

            Разностная стационарная система полностью управляема на $[0; m]$
            тогда и только тогда, когда
            \[
            \rank \left[ Q, PQ, \dots, P^{\overline m-1}Q \right] = n,
            \quad \text{где} \quad \overline m = \min(m, n).
            \]

            <div class="idea">
              <ol>
                <li>
                  Если $m \lt n$, то критерий остаётся таким же:
                  \[
                  \rank \left[ Q, PQ, \dots, P^{m-1} Q \right] = n;
                  \]
                </li>

                <li>
                  Если $m \geqslant n$, то
                  \[
                  \rank \left[
                  Q, PQ, \dots, P^{n-1} Q, P^n Q, \dots, P^{m-1} Q
                  \right] = n.
                  \]
                  По теореме Гамильтона-Кэли, $P^n, P^{n+1}, \dots, P^{m-1}$
                  выражаются в виде линейной комбинации через
                  $E, P, \dots, P^{n-1}$, поэтому $P^n Q, \dots, P^{m-1} Q$
                  линейно зависимы с предыдущими блоками, то есть
                  \[
                  \rank \left[ Q, PQ, \dots, P^{n-1} Q \right] = n.
                  \]
                </li>
              </ol>
            </div>

            <div class="proof">
              <!-- FIXME: расписать подробнее -->
              <ol>
                <li>
                  Если $m \lt n$, то критерий остаётся таким же:
                  \[
                  \rank \left[ Q, PQ, \dots, P^{m-1} Q \right] = n;
                  \]
                </li>

                <li>
                  Если $m \geqslant n$, то
                  \[
                  \rank \left[
                  Q, PQ, \dots, P^{n-1} Q, P^n Q, \dots, P^{m-1} Q
                  \right] = n.
                  \]
                  По теореме Гамильтона-Кэли, $P^n, P^{n+1}, \dots, P^{m-1}$
                  выражаются в виде линейной комбинации через
                  $E, P, \dots, P^{n-1}$, поэтому $P^n Q, \dots, P^{m-1} Q$
                  линейно зависимы с предыдущими блоками, то есть
                  \[
                  \rank \left[ Q, PQ, \dots, P^{n-1} Q \right] = n.
                  \]
                </li>
              </ol>
            </div>
          </div>
        </div>
      </li>

      <li class="question">
        <div class="name">
          Критерий Хаутуса полной управляемости линейной стационарной
          разностной системы
        </div>
        <div class="content">
          <div class="theorem">
            <i>(Критерий Хаутуса).</i>

            Линейная стационарная разностная система
            \[
            x(k+1) = P x(k) + Q u(k) + f(k)
            \]
            полностью управляема на $[0; m]$ тогда и только тогда, когда
            \[
            \rank \left[ sE - P, Q \right] = n
            \quad \forall s \in \mathbb{C}.
            \]

            <div class="idea">
              <!-- FIXME: расписать -->
              <span class="todo"></span>
            </div>

            <div class="proof">
              <!-- FIXME: расписать -->
              <span class="todo"></span>
            </div>
          </div>
        </div>
      </li>

      <h2 class="subtitle">
        19. Управляемость устойчивых стационарных разностных систем. Грамиан
        управляемости 
      </h2>

      <li class="question">
        <div class="name">
          Критерий равномерной асимптотической устойчивости линейной
          стационарной разностной системы
        </div>
        <div class="content">
          <div class="theorem">
            <i>(Критерий равномерной асимптотической устойчивости).</i>

            Линейная стационарная разностная система
            \[
            x(k+1) = P x(k), \quad k \in \Z
            \]
            равномерно асимптотически устойчива тогда и только тогда, когда
            \[
            \abs{\lambda_j(P)} \lt 1 \quad \forall j.
            \]
          </div>
        </div>
      </li>

      <li class="question">
        <div class="name">
          Критерий равномерной устойчивости линейной стационарной разностной
          системы
        </div>
        <div class="content">
          <div class="theorem">
            <i>(Критерий равномерной устойчивости).</i>

            Линейная стационарная разностная система
            \[
            x(k+1) = P x(k), \quad k \in \Z
            \]
            равномерно устойчива тогда и только тогда, когда
            \[
            \abs{\lambda_j(P)} \leqslant 1 \quad \forall j,
            \]
            причём если
            \[
            \abs{\lambda_j(P)} = 1,
            \]
            то у $\lambda_j(P)$ имеются только простые элементарные делители.
            <!-- FIXME: дать определение слову "элементарные" -->
          </div>
        </div>
      </li>

      <li class="question">
        <div class="name">
          Определение: грамиан управляемости для разностной системы
        </div>
        <div class="content">
          Рассмотрим линейную стационарную систему
          \[
          x(k+1) = P x(k) + Q u(k) + f(k).
          \]
          Будем предполагать, что она асимптотически устойчива, то есть
          \[
          \abs{\lambda_j(P)} \lt 1 \quad \forall j;
          \]
          тогда
          \[
          P^k \underset{k \to \infty}{\longrightarrow} 0.
          \]

          <div class="definition">
            Матрица
            \[
            U = \sum_{k=0}^\infty P^k Q Q^* (P^*)^k
            \]
            называется <i>грамианом управляемости</i> линейной стационарной
            асимптотически устойчивой разностной системы.
          </div>
        </div>
      </li>

      <li class="question">
        <div class="name">
          Теорема о полной управляемости асимптотически устойчивой разностной
          системы
        </div>
        <div class="content">
          Рассмотрим стационарную асимптотически устойчивую разностную систему
          \[
          x(k + 1) = P x(k) + Q u(k) + f(k), \quad m \geqslant n
          \]
          <!-- FIXME: а если $m \lt n$? -->
          и её грамиан управляемости
          \[
          U = \sum_{k=0}^\infty P^k Q Q^* (P^*)^k.
          \]

          <div class="theorem">
            Система полностью управляема тогда и только тогда, когда
            $\det U \neq 0$.

            <div class="idea">
              <!-- FIXME: расписать -->
              <span class="todo"></span>
            </div>

            <div class="proof">
              <!-- FIXME: расписать -->
              <span class="todo"></span>
            </div>
          </div>
        </div>
      </li>

      <li class="question">
        <div class="name">
          Алгоритм нахождения грамиана управляемости для разностной системы
        </div>
        <div class="content">
          Рассмотрим стационарную асимптотически устойчивую разностную систему
          \[
          x(k + 1) = P x(k) + Q u(k) + f(k)
          \]
          и её грамиан управляемости
          \[
          U = \sum_{k=0}^\infty P^k Q Q^* (P^*)^k.
          \]

          <div class="lemma">
            Грамиан управляемости $U$ удовлетворяет матричному уравнению
            Ляпунова
            \[
            PUP^* - U + Q Q^* = 0.
            \]

            <div class="idea">
              Проверяется подстановкой.
            </div>

            <div class="proof">
              <!-- FIXME: расписать -->
              <span class="todo"></span>
            </div>
          </div>

          Грамиан управляемости можно найти из матричного управления Ляпунова.
        </div>
      </li>

      <h2 class="subtitle">
        20. Задача наблюдения в линейных системах. Критерии полной
        наблюдаемости 
      </h2>

      <li class="question">
        <div class="name">
          Постановка и решение задачи наблюдения в линейных системах
        </div>
        <div class="content">
          Рассмотрим линейную систему
          \[
          \dot x = P(t) x + f(t).
          \]
          Предположим, что на $[0;T]$ ведётся <i>наблюдение</i>
          \[
          y = R(t) x + \varphi(t), \quad y \in \R^r.
          \]

          <div class="problem">
            По доступным наблюдениям определить вектор фазовых переменных
            $x(t) \; \forall t \in [0; T]$.

            <div class="solution">
              Рассмотрим общее решение в форме Коши:
              \[
              x(t) = Y(t) \paren{
              x_0 + \int\limits_0^t Y^{-1}(\tau) f(\tau) d\tau
              },
              \]
              где $Y(t)$ &mdash; матрицант. Подставим это выражение в уравнение
              наблюдателя:
              \[
              y(t) = R(t) Y(t) \paren{
              x_0 + \int\limits_0^t Y^{-1}(\tau) f(\tau) d\tau
              }
              + \varphi(t).
              \]
              Перенесём слагаемые, содержащие $x_0$, в левую часть, а все
              остальные &mdash; в правую:
              \[
              R(t) Y(t) x_0
              = y - R(t) Y(t) \int\limits_0^t Y^{-1}(\tau) f(\tau) d\tau
              - \varphi(t).
              \]
              Введя обозначения
              \[
              \begin{aligned}
              H(t) &:= R(t) Y(t) \\
              g(t) &:= y - H(t) \int\limits_0^t Y^{-1}(\tau) f(\tau) d\tau
              - \varphi(t),
              \end{aligned}
              \]
              уравнение можно переписать в виде
              \[
              H(t) x_0 = g(t).
              \]
            </div>
          </div>
        </div>
      </li>

      <li class="question">
        <div class="name">
          Определение: полностью наблюдаемая система
        </div>
        <div class="content">
          <div class="definition">
            Система
            \[
            \begin{aligned}
            \dot x &= P(t) x + f(t), \\
            y &= R(t) x + \varphi(t)
            \end{aligned}
            \]
            называется <i>полностью наблюдаемой</i>, если по наблюдениям $y(t)$
            на $[0; T]$ можно однозначно восстановить $x(0) = x_0$.
          </div>
        </div>
      </li>

      <li class="question">
        <div class="name">
          Критерии полной наблюдаемости линейной системы (2 штуки)
        </div>
        <div class="content">
          Рассмотрим систему
          \[
          \begin{aligned}
          \dot x &= P(t) x + f(t), \\
          y &= R(t) x + \varphi(t).
          \end{aligned}
          \]

          <div class="theorem">
            Система полностью наблюдаема на $[0;T]$ тогда и только тогда, когда
            столбцы матрицы $H(t) = R(t) Y(t)$ линейно независимы на $[0;T]$.

            <div class="idea">
              <!-- FIXME: расписать -->
              <span class="todo"></span>
            </div>

            <div class="proof">
              <!-- FIXME: расписать -->
              <span class="todo"></span>
            </div>
          </div>

          <div class="lemma">
            Столбцы $H(t)$ линейно независимы на $[0; T]$ тогда и только тогда,
            когда существуют
            \[
            0 \leqslant t_1 \lt t_2 \lt \dots \lt t_m \leqslant T,
            \quad m \leqslant n,
            \]
            для которых
            \[
            \rank \paren{
            \begin{array}{c}
            H(t_1) \\
            \vdots \\
            H(t_m)
            \end{array}
            } = n.
            \]

            <div class="idea">
              <!-- FIXME: расписать -->
              <span class="todo"></span>
            </div>

            <div class="proof">
              <!-- FIXME: расписать -->
              <span class="todo"></span>
            </div>
          </div>
        </div>
      </li>

      <h2 class="subtitle">
        21. Принцип двойственности
      </h2>

      <li class="question">
        <div class="name">
          Определение: система, двойственная к наблюдаемой
        </div>
        <div class="content">
          Рассмотрим систему
          \[
          \begin{aligned}
          \dot x &= P(t) x + f(t), \\
          y &= R(t) x + \varphi(t).
          \end{aligned}
          \]

          <div class="definition">
            <i>Системой, двойственной к наблюдаемой</i> называют систему
            \[
            \dot z = - P^*(t) z + R^*(t) u.
            \]
          </div>
        </div>
      </li>

      <li class="question">
        <div class="name">
          Определение: система, двойственная к управляемой
        </div>
        <div class="content">
          Рассмотрим систему
          \[
          \dot x = P(t) x + Q(t) u + f(t).
          \]

          <div class="definition">
            <i>Системой, двойственной к управляемой</i> называют систему
            \[
            \begin{aligned}
            \dot z &= -P^*(t) z, \\
            y &= \phantom{-} Q^*(t) z.
            \end{aligned}
            \]
          </div>
        </div>
      </li>

      <li class="question">
        <div class="name">
          Принцип двойственности
        </div>
        <div class="content">
          <div class="theorem">
            Система
            \[
            \begin{aligned}
            \dot x &= P(t) x + f(t), \\
            y &= R(t) x + \varphi(t)
            \end{aligned}
            \]
            полностью наблюдаема тогда и только тогда, когда двойственная к ней
            система
            \[
            \dot z = - P^*(t) z + R^*(t) u
            \]
            полностью управляема.

            <div class="idea">
              Из критериев полной управляемости и полной наблюдаемости известно,
              что соответственно строки матрицы $B(t) = Z^{-1}(t) R^*(t)$ и
              столбцы матрицы $H(t) = R(t) Y(t)$ должны быть линейно независимы.
              Нужно показать, что они совпадают, то есть $H^*(t) \equiv B(t)$.
              Вопрос сводится к тому, выполнено ли тождество
              $Y^*(t) \equiv Z^{-1}(t)$. Сначала доказываем, что
              \[
              \dv{}{t} \paren{Y^*(t) Z(t)} \equiv 0,
              \]
              то есть
              \[
              Y^*(t) Z(t) \equiv C,
              \]
              потом используем тот факт, что $Y(t)$ и $Z(t)$ &mdash; матрицанты,
              поэтому
              \[
              Y^*(t) Z(t) \equiv 0,
              \]
              или, иначе,
              \[
              Y^*(t) \equiv Z^{-1}(t).
              \]
            </div>

            <div class="proof">
              Пусть $Y(t)$ &mdash; матрицант наблюдаемой системы, а $Z(t)$
              &mdash; матрицант управляемой системы.

              <p>
              Известно, что система полностью наблюдаема тогда и только тогда,
              когда столбцы матрицы $H(t) \bydef= R(t) Y(t)$ линейно независимы.
              </p>

              <p>
              Известно, что система полностью управляема  тогда и только тогда,
              когда строки матрицы $B(t) \bydef= Z^{-1}(t) R^*(t)$ линейно
              независимы.
              </p>

              Покажем, что строки $B(t)$ и столбцы $H(t)$ совпадают:
              \[
              Y^*(t) R^*(t) = H^*(t) \overset{?}{=} B(t) = Z^{-1}(t) R^*(t).
              \]

              Нужно показать, что
              \[
              Y^*(t) \equiv Z^{-1}(t).
              \]

              Рассмотрим
              \[
              \dv{}{t} \paren{Y^*(t) Z(t)}
              = \dot{Y}^*(t) Z(t) + Y^*(t) \dot Z(t).
              \]

              Из курса дифференциальных уравнений известно, что фундаментальная
              матрица удовлетворяет соответствующему матричному уравнению:
              \[
              \begin{aligned}
              \dot Y(t) &= P(t) Y(t), \\
              \dot Z(t) &= -P^*(t) Z(t),
              \end{aligned}
              \]
              поэтому
              \[
              \dot{Y}^*(t) Z(t) + Y^*(t) \dot Z(t) 
              = Y^*(t) P^*(t) Z(t) - Y^*(t) P^*(t) Z(t) \equiv 0.
              \]
              Значит,
              \[
              Y^*(t) Z(t) \equiv C.
              \]

              Так как $Y(t)$ и $Z(t)$ &mdash; матрицанты, то
              \[
              Y^*(0) Z(0) = E,
              \]
              поэтому
              \[
              Y^*(t) Z(t) \equiv E,
              \]
              или, в силу невырожденности матрицы $Z(t)$,
              \[
              Y^*(t) \equiv Z^{-1}(t),
              \]
              что и требовалось показать.
            </div>
          </div>
        </div>
      </li>

      <h2 class="subtitle">
        22. Достаточное условие полной наблюдаемости 
      </h2>

      <li class="question">
        <div class="name">
          Достаточное условие полной наблюдаемости
        </div>
        <div class="content">
          Рассмотрим систему
          \[
          \begin{aligned}
          \dot x &= P(t) x + f(t), \\
          y &= R(t) x + \varphi(t)
          \end{aligned}
          \]
          и двойственную к ней
          \[
          \dot z = - P^*(t) z + R^*(t) u.
          \]
          Будем считать, что
          \[
          \begin{aligned}
          R(t) &\in C^{n-1}[0;T] \\
          P(t) &\in C^{n-2}[0;T].
          \end{aligned}
          \]
          Введём обозначения:
          \[
          \begin{aligned}
          S_0(t) &= R^*(t), \\
          S_1(t) &= \dot S_0(t) + P^*(t) S_0(t), \\
          &\dots \\
          S_{n-1}(t) &= \dot S_{n-2}(t) + P^*(t) S_{n-2}(t),
          \end{aligned}
          \]
          считаем, что
          <!-- FIXME: кажется, S_k \in C^{n-1-k} -->
          \[
          S_k(t) \in C[0;T], \quad k = \overline{1, n-1}.
          \]

          <div class="theorem">
            <i>(Достаточное условие полной наблюдаемости).</i>

            Для полной наблюдаемости системы
            \[
            \begin{aligned}
            \dot x &= P(t) x + f(t), \\
            y &= R(t) x + \varphi(t)
            \end{aligned}
            \]
            на интервале $[0;T]$ достаточно, чтобы нашёлся момент времени
            $\tau \in [0;T]$ такой, что
            \[
            \rank S(\tau) = n.
            \]

            <div class="idea">
              <!-- FIXME: расписать -->
              <span class="todo"></span>
            </div>

            <div class="proof">
              <!-- FIXME: расписать -->
              <span class="todo"></span>
            </div>
          </div>
        </div>
      </li>

      <h2 class="subtitle">
        23. Задача дискретной наблюдаемости
      </h2>

      <li class="question">
        <div class="name">
          Постановка задачи дискретной наблюдаемости
        </div>
        <div class="content">
          Рассмотрим систему с наблюдением
          \[
          \begin{aligned}
          \dot x &= P(t) x + f(t), \\
          y &= R(t) x + \varphi(t).
          \end{aligned}
          \]
          Предположим, что известны наблюдения в дискретные моменты времени
          \[
          y(t_1), \dots, y(t_m), \quad t_1, \dots, t_m \in [0;T].
          \]

          <div class="problem">
            <!--
              FIXME: почему достаточно знать x_0, чтобы однозначно
              восстановить вектор фазового состояния $x(t)$? Вернее,
              почему $x(t)$ &mdash; вектор фазового состояния?
            -->
            По известным наблюдениям однозначно определить вектор $x(0) = x_0$.
          </div>
        </div>
      </li>

      <li class="question">
        <div class="name">
          Теоремы о разрешимости задачи дискретной наблюдаемости
        </div>
        <div class="content">
          Рассмотрим задачу дискретной наблюдаемости системы
          \[
          \begin{aligned}
          \dot x &= P(t) x + f(t), \\
          y &= R(t) x + \varphi(t).
          \end{aligned}
          \]
          
          <div class="theorem">
            Пусть моменты времени $t_1, \dots, t_m \in [0;T]$ заданы заранее.
            Тогда задача дискретной наблюдаемости разрешима тогда и только
            тогда, когда
            \[
            \rank
            \begin{pmatrix}
            H(t_1) \\
            \vdots \\
            H(t_m)
            \end{pmatrix}
            = n.
            \]

            <div class="idea">
              <!-- FIXME: расписать -->
              <span class="todo"></span>
            </div>

            <div class="proof">
              <!-- FIXME: расписать -->
              <span class="todo"></span>
            </div>
          </div>
          
          <div class="theorem">
            Пусть моменты времени $t_1, \dots, t_m \in [0;T]$ произвольны. Тогда
            задача дискретной наблюдаемости разрешима тогда и только тогда,
            когда система полностью наблюдаема.

            <div class="idea">
              <!-- FIXME: расписать -->
              <span class="todo"></span>
            </div>

            <div class="proof">
              <!-- FIXME: расписать -->
              <span class="todo"></span>
            </div>
          </div>
        </div>
      </li>

      <h2 class="subtitle">
        24. Критерии Калмана и Хаутуса полной наблюдаемости
      </h2>

      <li class="question">
        <div class="name">
          Критерий Калмана полной наблюдаемости
        </div>
        <div class="content">
          Рассмотрим наблюдаемую стационарную систему
          \[
          \begin{aligned}
          \dot x &= Px + f(t), \\
          y &= Rx + \varphi(t),
          \end{aligned}
          \quad t \in [0;T]
          \]
          и двойственную к ней управляемую систему
          \[
          \dot z = -P^*z + R^* u,
          \]
          для которой составим вспомогательные матрицы
          \[
          \begin{aligned}
          S_0 &\bydef = R^* \\
          S_1 &= P^* R^* \\
          &\phantom{=} \dots \\
          S_{n-1} &= (P^*)^{n-1} R^*.
          \end{aligned}
          \]
          Введём обозначение:
          \[
          S^* \bydef= \left[ R^*, P^* R^*, \dots, (P^*)^{n-1} R^* \right].
          \]

          <div class="theorem">
            <i>(Критерий Калмана полной наблюдаемости).</i>
            Система полностью наблюдаема на $[0;T]$ тогда и только тогда, когда
            \[
            \rank S = \rank
            \begin{bmatrix}
            R \\
            RP \\
            \vdots \\
            RP^{n-1}
            \end{bmatrix} = n.
            \]

            <div class="idea">
              <!-- FIXME: расписать -->
              <span class="todo"></span>
            </div>

            <div class="proof">
              <!-- FIXME: расписать -->
              <span class="todo"></span>
            </div>
          </div>
        </div>
      </li>

      <li class="question">
        <div class="name">
          Критерий Хаутуса полной наблюдаемости
        </div>
        <div class="content">
          Рассмотрим наблюдаемую стационарную систему
          \[
          \begin{aligned}
          \dot x &= Px + f(t), \\
          y &= Rx + \varphi(t),
          \end{aligned}
          \quad t \in [0;T]
          \]
          и двойственную к ней управляемую систему
          \[
          \dot z = -P^*z + R^* u.
          \]

          <div class="theorem">
            <i>(Критерий Хаутуса полной наблюдаемости).</i>

            Система полностью наблюдаема на промежутке $[0;T]$ тогда и только
            тогда, когда для любого $s \in \mathbb{C}$
            \[
            \rank
            \begin{bmatrix}
            sE + P^* & R^*
            \end{bmatrix}
            =
            \rank
            \begin{bmatrix}
            sE + P \\
            R
            \end{bmatrix}
            = n.
            \]

            <div class="idea">
              <!-- FIXME: расписать -->
              <span class="todo"></span>
            </div>

            <div class="proof">
              <!-- FIXME: расписать -->
              <span class="todo"></span>
            </div>
          </div>
        </div>
      </li>

      <h2 class="subtitle">
        25. Декомпозиция линейной наблюдаемой системы. Следствие
      </h2>

      <li class="question">
        <div class="name">
          Декомпозиция линейной наблюдаемой системы. Следствие
        </div>
        <div class="content">
          Рассмотрим наблюдаемую стационарную систему
          \[
          \begin{aligned}
          \dot x &= Px + f(t), \\
          y &= Rx + \varphi(t),
          \end{aligned}
          \quad t \in [0;T].
          \]
          Предположим, что она не является полностью наблюдаемой; тогда
          \[
          \rank S = \rank
          \begin{bmatrix}
          R \\
          RP \\
          \vdots \\
          RP^{n-1}
          \end{bmatrix} = m \lt n.
          \]

          <div class="statement">
            Линейная оболочка $\Lin S$ инвариантна относительно умножения на
            $P$, то есть
            \[
            \forall l \in \Lin S \quad lP \in \Lin S.
            \]

            <div class="idea">
              <!-- FIXME: расписать -->
              <span class="todo"></span>
            </div>

            <div class="proof">
              <!-- FIXME: расписать -->
              <span class="todo"></span>
            </div>
          </div>

          <div class="theorem">
            Если система не полностью наблюдаема, то существует неособое
            преобразование, приводящее к декомпозиции исходной системы на
            наблюдаемую и ненаблюдаемую части.

            <div class="idea">
              <!-- FIXME: расписать -->
              <span class="todo"></span>
            </div>

            <div class="proof">
              <!-- FIXME: расписать -->
              <span class="todo"></span>
            </div>
          </div>

          <div class="corollary">
            Для матриц $P_{11}$ и $R_1$ наблюдаемой подсистемы справедливо:
            \[
            \rank
            \begin{bmatrix}
            R_1 \\
            R_1 P_{11} \\
            \vdots \\
            R_1 P_{11}^{m-1}
            \end{bmatrix}
            = m.
            \]

            <div class="idea">
              <!-- FIXME: расписать -->
              <span class="todo"></span>
            </div>

            <div class="proof">
              <!-- FIXME: расписать -->
              <span class="todo"></span>
            </div>
          </div>
        </div>
      </li>

      <h2 class="subtitle">
        26. Наблюдаемость устойчивых линейных стационарных систем.
        Интегральный критерий линейной независимости. Грамиан наблюдаемости
      </h2>

      <li class="question">
        <div class="name">
          Определение: грамиан наблюдаемости
        </div>
        <div class="content">
          Рассмотрим асимптотически устойчивую линейную стационарную систему
          \[
          \begin{aligned}
          \dot{x} &= P x + f(t) \\
          y &= R x + \varphi(t),
          \end{aligned}
          \qquad \Re \lambda_j(P) \lt 0.
          \]

          <div class="definition">
            Матрица
            \[
            V = \int\limits_0^\infty Y^*(\tau) R^* R Y(\tau) d\tau
            \]
            называется <i>грамианом наблюдаемости</i>.
          </div>

          <div class="remark">
            Используя обозначение
            \[
            H(t) \bydef= R \, Y(t),
            \]
            грамиан наблюдаемости можно переписать в виде
            \[
            V = \int\limits_0^\infty H^*(\tau) H(\tau) d\tau.
            \]
          </div>
        </div>
      </li>

      <li class="question">
        <div class="name">
          Свойства грамиана наблюдаемости
        </div>
        <div class="content">
          <!--
            FIXME: добавить свойства грамиана (они такие же, как и у грамиана
            управляемости)
          -->

          <div class="lemma">
            Грамиан наблюдаемости удовлетворяет матричному уравнению Ляпунова:
            \[
            P^* V + VP + R^* R = 0.
            \]

            <div class="idea">
              Проверяется подстановкой.
            </div>

            <div class="proof">
              <!-- FIXME: расписать -->
              <span class="todo"></span>
            </div>
          </div>
        </div>
      </li>

      <!--
        NOTE: интегральный критерий линейной независимости можно найти в
        билете 1.
      -->

      <li class="question">
        <div class="name">
          Критерий полной наблюдаемости устойчивой стационарной системы
        </div>
        <div class="content">
          Рассмотрим асимптотически устойчивую линейную стационарную систему
          \[
          \begin{aligned}
          \dot{x} &= P x + f(t) \\
          y &= R x + \varphi(t),
          \end{aligned}
          \qquad \Re \lambda_j(P) \lt 0.
          \]

          <div class="theorem">
            <i>
              (Критерий полной наблюдаемости устойчивой стационарной системы).
            </i>

            Асимптотически устойчивая система полностью наблюдаема тогда и
            только тогда, когда
            \[
            \det V \neq 0.
            \]

            <div class="idea">
              <!-- FIXME: расписать -->
              <span class="todo"></span>
            </div>

            <div class="proof">
              <!-- FIXME: расписать -->
              <span class="todo"></span>
            </div>
          </div>
        </div>
      </li>

      <h2 class="subtitle">
        27. Задача наблюдения в линейных разностных системах
      </h2>

      <li class="question">
        <div class="name">
          Постановка задачи наблюдения для разностных систем
        </div>
        <div class="content">
          Рассмотрим разностную систему
          \[
          x(k+1) = P(k) x(k) + f(k), \quad k \in \Z.
          \]
          Введём наблюдение
          \[
          y(k) = R(k) x(k) + \varphi(k), \quad k = \overline{0,m-1}.
          \]

          <div class="problem">
            По имеющимся наблюдениям $y(0), \dots, y(m-1)$ однозначно
            восстановить вектор $x(0) = x_0$.

            <div class="solution">
              Установим связь между наблюдаемыми величинами и вектором $x_0$:
              \[
              \begin{aligned}
              k = 0: & & y(0) &= R(0) x(0) + \varphi(0) \\
                     & & x(1) &= P(0) x(0) + f(0) \\
                     \\
              k = 1: & & y(1) &= R(1) x(1) + \varphi(1) \\
                     & & x(2) &= P(1) x(1) + f(1) \\
                     & & &\vdots
              \end{aligned}
              \]
              Введём обозначения:
              \[
              \begin{gathered}
              D =
              \begin{bmatrix}
              R(0) \\
              R(1) P(0) \\
              \vdots \\
              R(m-1) P(m-2) \cdots P(0)
              \end{bmatrix}, \\
              \eta =
              \begin{bmatrix}
              y(0) - \varphi(0) \\
              y(1) - \varphi(1) - R(1) f(0) \\
              y(2) - \varphi(2) - R(2) P(1) f(0) - R(2) f(1) \\
              \vdots \\
              y(m-1) - \varphi(m-1)
              - R(m-1) \sum_{k=0}^{m-1} f(k) \prod_{j=k+1}^{m-1} P(j)
              \end{bmatrix},
              \end{gathered}
              \]
              <!-- FIXME: проверить формулу -->
              тогда
              \[
              D x_0 = \eta.
              \]
            </div>
          </div>
        </div>
      </li>

      <li class="question">
        <div class="name">
          Теорема о полной наблюдаемости разностной системы
        </div>
        <div class="content">
          Рассмотрим разностную наблюдаемую систему
          \[
          \begin{aligned}
          x(k+1) = P(k) x(k) + f(k), \\
          y(k) = R(k) x(k) + \varphi(k), \\
          \end{aligned}
          \qquad k = \overline{0,m-1}.
          \]
          Используя обозначения
          \[
          \begin{gathered}
          D =
          \begin{bmatrix}
          R(0) \\
          R(1) P(0) \\
          \vdots \\
          R(m-1) P(m-2) \cdots P(0)
          \end{bmatrix}, \\
          \eta =
          \begin{bmatrix}
          y(0) - \varphi(0) \\
          y(1) - \varphi(1) - R(1) f(0) \\
          y(2) - \varphi(2) - R(2) P(1) f(0) - R(2) f(1) \\
          \vdots \\
          y(m-1) - \varphi(m-1)
          - R(m-1) \sum_{k=0}^{m-1} f(k) \prod_{j=k+1}^{m-1} P(j)
          \end{bmatrix},
          \end{gathered}
          \]
          система дискретных значений системы запишется в виде
          \[
          D x_0 = \eta.
          \]

          <div class="theorem">
            Разностная система полностью наблюдаема тогда и только тогда, когда
            \[
            \rank D = n.
            \]

            <div class="idea">
              <!-- FIXME: расписать -->
              <span class="todo"></span>
            </div>

            <div class="proof">
              <!-- FIXME: расписать -->
              <span class="todo"></span>
            </div>
          </div>
        </div>
      </li>

      <h2 class="subtitle">
        28. Наблюдаемость стационарных разностных систем. Критерий Хаутуса
      </h2>

      <li class="question">
        <div class="name">
          Теорема о полной наблюдаемости разностной стационарной системы
        </div>
        <div class="content">
          Рассмотрим стационарную разностную наблюдаемую систему
          \[
          \begin{aligned}
          x(k+1) = P x(k) + f(k), \\
          y(k) = R x(k) + \varphi(k), \\
          \end{aligned}
          \qquad k = \overline{0,m-1}.
          \]
          Выпишем значения наблюдателя: для любого $k = \overline{0,m-1}$
          \[
          y(k) = R \left[
          P^k x_0 + P^{k-1} f(0) + P^{k-2} f(1) + \dots + P f(k-2) + f(k-1)
          \right]
          + \varphi(k).
          \]
          Введём обозначения:
          \[
          \begin{gathered}
          D =
          \begin{bmatrix}
          R \\
          R P \\
          \vdots \\
          R P^{m-1}
          \end{bmatrix}, \\
          \eta =
          \begin{bmatrix}
          y(0) - \varphi(0) \\
          y(1) - \varphi(1) - R f(0) \\
          y(2) - \varphi(2) - R P f(0) - R f(1) \\
          \vdots \\
          y(m-1) - \varphi(m-1)
          - R \sum_{k=0}^{m-2} f(k) P^{m-2-k}
          \end{bmatrix},
          \end{gathered}
          \]
          тогда
          \[
          D x_0 = \eta.
          \]

          <div class="theorem">
            <!-- FIXME: это, считай, критерий Калмана -->
            Стационарная разностная система полностью наблюдаема тогда и только
            тогда, когда
            \[
            \rank D = n.
            \]

            <div class="idea">
              <!-- FIXME: расписать -->
              <span class="todo"></span>
            </div>

            <div class="proof">
              <!-- FIXME: расписать -->
              <span class="todo"></span>
            </div>
          </div>

          <!--
            FIXME: добавить уточнённый критерий Калмана, основанный на том, как
            соотносятся $m$ и $n$.
          -->

          <!--
            FIXME: нужно ли добавлять лемму о декомпозиции в случае неполной
            наблюдаемости (rank D \lt n)?
          -->
        </div>
      </li>

      <li class="question">
        <div class="name">
          Критерий Хаутуса полной наблюдаемости разностной системы
        </div>
        <div class="content">
          Рассмотрим стационарную разностную наблюдаемую систему
          \[
          \begin{aligned}
          x(k+1) = P x(k) + f(k), \\
          y(k) = R x(k) + \varphi(k), \\
          \end{aligned}
          \qquad k = \overline{0,m-1}.
          \]

          <div class="theorem">
            <i>(Критерий Хаутуса полной наблюдаемости разностной системы).</i>
            Разностная система полностью наблюдаема тогда и только тогда, когда
            для любого $s \in \mathbb{C}$
            \[
            \rank
            \begin{bmatrix}
            R \\
            sE - P
            \end{bmatrix}
            = n.
            \]

            <div class="idea">
              <!-- FIXME: расписать -->
              <span class="todo"></span>
            </div>

            <div class="proof">
              <!-- FIXME: расписать -->
              <span class="todo"></span>
            </div>
          </div>
        </div>
      </li>

      <h2 class="subtitle">
        29. Наблюдаемость устойчивых стационарных разностных систем.
        Грамиан наблюдаемости
      </h2>

      <li class="question">
        <div class="name">
          Определение: грамиан наблюдаемости для разностной системы
        </div>
        <div class="content">
          Рассмотрим разностную наблюдаемую систему
          \[
          \begin{aligned}
          x(k+1) = P x(k) + f(k), \\
          y(k) = R x(k) + \varphi(k), \\
          \end{aligned}
          \qquad k \in [0;m-1].
          \]
          Будем считать, что она асимптотически устойчива, то есть
          \[
          \abs{\lambda_j(P)} \lt 1 \quad \forall j \in \overline{1,n},
          \]
          поэтому
          \[
          P^k \underset{k \to \infty}{\longrightarrow} 0.
          \]

          <div class="definition">
            Матрицу
            \[
            V = \sum_{k=0}^\infty (P^*)^k R^* R P^k
            \]
            называют <i>грамианом наблюдаемости</i> для разностной системы.
          </div>
        </div>
      </li>

      <li class="question">
        <div class="name">
          Свойства грамиана наблюдаемости разностной системы
        </div>
        <div class="content">
          Рассмотрим устойчивую разностную наблюдаемую систему
          \[
          \begin{aligned}
          x(k+1) = P x(k) + f(k), \\
          y(k) = R x(k) + \varphi(k), \\
          \end{aligned}
          \qquad k \in [0;m-1]
          \]
          и её грамиан наблюдаемости
          \[
          V = \sum_{k=0}^\infty (P^*)^k R^* R P^k.
          \]

          <!-- FIXME: добавить свойства -->

          <div class="lemma">
            Грамиан управляемости удовлетворяет матричному уравнению Ляпунова:
            \[
            P^* V P - V + R^* R = 0.
            \]

            <div class="idea">
              Проверяется подстановкой.
            </div>

            <div class="proof">
              <!-- FIXME: расписать -->
              <span class="todo"></span>
            </div>
          </div>
        </div>
      </li>

      <li class="question">
        <div class="name">
          Критерий полной наблюдаемости для устойчивой стационарной разностной
          системы
        </div>
        <div class="content">
          Рассмотрим устойчивую разностную наблюдаемую систему
          \[
          \begin{aligned}
          x(k+1) = P x(k) + f(k), \\
          y(k) = R x(k) + \varphi(k), \\
          \end{aligned}
          \qquad k \in [0;m-1]
          \]
          и её грамиан наблюдаемости
          \[
          V = \sum_{k=0}^\infty (P^*)^k R^* R P^k.
          \]

          <div class="theorem">
            Устойчивая стационарная разностная система полностью наблюдаема на
            $[0;m]$ тогда и только тогда, когда
            <!--
              FIXME: скорее всего, $[0;m]$ можно опустить, потому что из
              наблюдаемости на $[0;m]$ следует наблюдаемость на $[0;M]$, где
              $M \gt m$
            -->
            \[
            \det V \neq 0.
            \]

            <div class="idea">
              <!-- FIXME: расписать -->
              <span class="todo"></span>
            </div>

            <div class="proof">
              <!-- FIXME: расписать -->
              <span class="todo"></span>
            </div>
          </div>
        </div>
      </li>

      <h2 class="subtitle">
        30. Общая постановка задачи стабилизации движения. Система в
        отклонениях
      </h2>

      <li class="question">
        <div class="name">
          Общая постановка задачи стабилизации движения
        </div>
        <div class="content">
          Рассмотрим движение системы
          \[
          \dot{y} = G(t, y, v).
          \]

          Будем предполагать, что решена задача программного управления: для
          заданных начальных данных $y(t_0) = y_0$ построено программное
          управление $v = v_p(t)$. Тогда уравнение программного движения
          запишем как
          \[
          y = y_p(t, t_0, y_0, v_p(t)).
          \]

          <div class="problem">
            Найти дополнительные управляющие воздействия, при которых
            построенное программное движение $y_p$ будет асимптотически
            устойчиво по Ляпунову.
          </div>
        </div>
      </li>

      <li class="question">
        <div class="name">
          Вывод системы в отклонениях для задачи стабилизации
        </div>
        <div class="content">
          Рассмотрим движение системы
          \[
          \dot{y} = G(t, y, v)
          \]
          с программным управлением $v = v_p(t)$, построенным для начальных
          данных $y(t_0) = y_0$.

          <p>
          Проведём замену переменных:
          \[
          \left\{
          \begin{aligned}
          y &= y_p(t) + x \\
          v &= v_p(t) + u
          \end{aligned}
          \right.
          \implies
          \left\{
          \begin{aligned}
          x &= y - y_p(t) \\
          u &= v - v_p(t),
          \end{aligned}
          \right.
          \]
          где $x$ и $u$ являются отклонениями от программного движения
          и программного управления соответственно.
          </p>

          <p>
          Тогда система примет вид
          \[
          \dot{x} = G(t, y_p(t) + x, v_p(t) + u) - G(t, y_p(t), v_p(t))
          = F(t, x, u).
          \]
          </p>

          <div class="definition">
            Полученную систему называют <i>системой в отклонениях</i>.
          </div>

          <p>
          Задача заключается в построении такого управления, при котором
          нулевое решение системы в отклонениях будет асимптотически устойчиво.
          </p>
        </div>
      </li>

      <h2 class="subtitle">
        31. Стабилизация линейных стационарных систем в случае полной обратной
        связи. Метод неопределённых коэффициентов. Понятие времени переходного
        процесса
      </h2>

      <li class="question">
        <div class="name">
          Стабилизация линейной стационарной системы в случае полной обратной
          связи
        </div>
        <div class="content">
          Рассмотрим стационарную систему в отклонениях:
          \[
          \dot{x} = P x + Q u.
          \]

          <div class="definition">
            Управление вида $u = C x$, где $C$ &mdash; некоторая постоянная
            матрица, называется <i>допустимым управлением вида линейной
              обратной связи</i>.
          </div>

          Если все компоненты вектора $x$ измеримы, то линейная обратная связь
          называется <i>полной</i>.

          <div class="problem">
            Построить управление вида полной линейной обратной связи, при
            котором замкнутая система
            \[
            \dot{x} = (P + QC) x
            \]
            асимптотически устойчива по Ляпунову, то есть
            \[
            \Re [\lambda_j (P + QC)] \lt 0.
            \]
          </div>
        </div>
      </li>

      <li class="question">
        <div class="name">
          Метод неопределённых коэффициентов построения стабилизирующего
          управления
        </div>
        <div class="content">
          Рассмотрим стационарную систему в отклонениях:
          \[
          \dot{x} = P x + Q u.
          \]
          Управление будем искать в виде полной обратной связи: $u = Cx$.

          <p>
          Рассмотрим характеристический полином матрицы замкнутой системы:
          \[
          \varphi(\lambda) = \det (\lambda E - (P + QC))
          = \lambda^n + \alpha_1(C) \lambda^{n-1} + \cdots + \lambda_n(C).
          \]
          </p>

          <div class="definition">
            Собственные числа матрицы замкнутой системы называются
            <i>неуправляемыми</i>, если они не зависят от выбора матрицы $C$.
          </div>

          <p>
          Выберем эталонные собственные числа $\mu_1, \dots, \mu_n: \;
          \Re (\mu_j) \lt 0$. Тогда эталонный полином запишется в виде
          \[
          \psi(\lambda) = \prod_{i=1}^n (\lambda - \mu_i)
          = \lambda^n + \beta_1 \lambda^{n-1} + \cdots + \beta_n.
          \]
          Приравняем полиномы $\varphi(\lambda) = \psi(\lambda)$: получим
          систему уравнений
          \[
          \left\{
          \begin{aligned}
          \alpha_1(C) &= \beta_1 \\
          &\dots \\
          \alpha_n(C) &= \beta_n.
          \end{aligned}
          \right.
          \]
          Найдя из этой системы $C$, получим искомое управление.
          </p>
        </div>
      </li>

      <li class="question">
        <div class="name">
          Определение: время переходного процесса
        </div>
        <div class="content">
          <div class="definition">
            Время $T$, необходимое системе стабилизации для подавления
            начального отклонения $x_0$ до величины безразличия $\varepsilon$:
            \[
            x(T) = \varepsilon,
            \]
            называется <i>временем переходного процесса</i>.
          </div>

          <div class="remark">
            Чем меньше собственное число, тем меньше время переходного
            процесса, но тем больше коэффициент усиления сигнала.
          </div>
        </div>
      </li>

      <h2 class="subtitle">
        32. Лемма о количестве неуправляемых собственных чисел 
      </h2>

      <li class="question">
        <div class="name">
          Лемма о количестве неуправляемых собственных чисел линейной
          стационарной системы
        </div>
        <div class="content">
          Рассмотрим стационарную систему
          \[
          \dot{x} = P x + Q u, \quad \text{где} \quad u = Cx.
          \]
          <div class="lemma">
            Если для системы ранг матрицы Калмана $\rank S = m \lt n$, то
            замкнутая система
            \[
            \dot{x} = (P + QC) x
            \]
            имеет $n - m$ неуправляемых собственных чисел.

            <div class="idea">
              Проверяется декомпозицией системы на управляемую и неуправляемую
              части, после чего используется тот факт, что спектр
              блочно-диагональной матрицы равен объединению спектров блоков на
              диагонали.
            </div>

            <div class="proof">
              Известно, что существует невырожденное преобразование $x = T y$,
              приводящее к декомпозиции системы на управляемую и неуправляемую
              подсистемы:
              \[
              \paren{
              \begin{array}{c}
              \dot{y}_1 \\
              \dot{y}_2
              \end{array}
              }
              =
              \paren{
              \begin{array}{cc}
              P_{11} & P_{12} \\
              0 & P_{22}
              \end{array}
              }
              \paren{
              \begin{array}{c}
              y_1 \\
              y_2
              \end{array}
              }
              +
              \paren{
              \begin{array}{c}
              Q_1 \\
              0
              \end{array}
              }
              u,
              \]
              причём
              \[
              u = Cx = CTy.
              \]

              Обозначив $CT =\paren{C_1, C_2}$, замкнём её:
              \[
              \paren{
              \begin{array}{c}
              \dot{y}_1 \\
              \dot{y}_2
              \end{array}
              }
              =
              \paren{
              \begin{array}{cc}
              P_{11} + Q_1 C_1 & P_{12} + Q_1 C_2 \\
              0 & P_{22}
              \end{array}
              }
              \paren{
              \begin{array}{c}
              y_1 \\
              y_2
              \end{array}
              }
              \]

              Спектр матрицы замкнутой системы представляет собой объединение
              спектров диагональных блоков. Так как матрица $P_{22}$ не зависит
              от выбора $C$, её собственные числа всегда лежат в спектре.

              <p>
              Они неуправляемы, их количество:
              \[
              \dim P_{22} = n - m.
              \]
              </p>
            </div>
          </div>
        </div>
      </li>

      <h2 class="subtitle">
        33. Лемма об управлении спектром линейной системы с матрицей Фробениуса
      </h2>

      <li class="question">
        <div class="name">
          Лемма об управлении спектром линейной системы с матрицей Фробениуса
        </div>
        <div class="content">
          Рассмотрим управляемую подсистему системы в отклонениях:
          \[
          \dot{y} = P_0 y + q_0 u.
          \]
          Предположим, что
          \[
          P_0 = \paren{
          \begin{array}{ccccc}
          0 & 0 & \dots & 0 & -\alpha_m \\
          1 & 0 & \dots & 0 & -\alpha_{m-1} \\
          \vdots & \vdots & \ddots & \vdots & \vdots \\
          0 & 0 & \dots & 0 & -\alpha_2 \\
          0 & 0 & \dots & 1 & -\alpha_1
          \end{array}
          },
          \qquad
          q_0 = \paren{
          \begin{array}{c}
          1 \\
          0 \\
          \vdots \\
          0
          \end{array}
          }.
          \]

          Управление ищем в виде полной обратной связи: $u = C y$.

          <div class="lemma">
            Для любого набора $\mu_1, \dots, \mu_m \in \mathbb{C}$ можно
            выбрать $C$ так, чтобы спектр матрицы замкнутой системы
            $P_0 + q_0 C$ совпадал с $\mu_1, \dots, \mu_m$.

            <div class="idea">
              Составляем матрицу
              \[
              K_0 = \paren{
              \begin{array}{ccccc}
              \alpha_{m - 1} & \alpha_{m-2} & \dots & \alpha_1 & 1 \\
              \alpha_{m-2} & \dots & \alpha_1 & 1 & 0 \\
              \vdots & \rddots & \rddots & \rddots & \vdots \\
              \alpha_1 & 1 & 0 & \dots & 0 \\
              1 & 0 & 0 & \dots & 0
              \end{array}
              },
              \]
              проводим замену переменных $y = K_0 z$, матрица снова
              фробениусова, замыкаем систему управлением $u = \gamma z$,
              находим из матрицы замкнутой системы полином.
            </div>

            <div class="proof">
              Проведём замену переменных: $y = K_0 z$, где $K_0$ удовлетворяет
              уравнению
              \[
              P_0^* = K_0^{-1} P_0 K_0, \quad \text{или} \quad K_0 P_0^*
              = P_0 K_0.
              \]
              Решая его методом Гаусса, получим, что
              \[
              K_0 = \paren{
              \begin{array}{ccccc}
              \alpha_{m - 1} & \alpha_{m-2} & \dots & \alpha_1 & 1 \\
              \alpha_{m-2} & \dots & \alpha_1 & 1 & 0 \\
              \vdots & \rddots & \rddots & \rddots & \vdots \\
              \alpha_1 & 1 & 0 & \dots & 0 \\
              1 & 0 & 0 & \dots & 0
              \end{array}
              }.
              \]
              Тогда управляемая подсистема примет вид
              \[
              \dot{z} = K_0^{-1} P_0 K_0 z + K_0^{-1} q_0 u.
              \]

              Используя
              \[
              K_0 \bar{q}_0 = q_0 = \paren{
              \begin{array}{c}
              1 \\
              0 \\
              \vdots \\
              0
              \end{array}
              },
              \implies
              \bar{q}_0 = K_0^{-1} q_0 = \paren{
              \begin{array}{c}
              0 \\
              0 \\
              \vdots \\
              1
              \end{array}
              },
              \]
              окончательно получаем:
              \[
              \dot{z} = P_0^* z + \bar q_0 u.
              \]

              <p>
              Для этой системы будем строить стабилизационное управление
              $u = \gamma z$, доставляющее спектр $\mu_1, \dots, \mu_m$.
              Используем МНК: замыкаем систему
              \[
              P_0^* + \bar q_0 \gamma = \paren{
              \begin{array}{ccccc}
              0 & 1 & \dots & 0 & 0 \\
              0 & 0 & \dots & 0 & 0 \\
              \vdots & \vdots & \ddots & \vdots & \vdots \\
              0 & 0 & \dots & 0 & 1 \\
              \gamma_m - \alpha_m & \gamma_{m-1} - \alpha_{m-1} & \dots
              & \gamma_2 - \alpha_2 & \gamma_1 - \alpha_1
              \end{array}
              }
              \]
              &mdash; матрица Фробениуса для
              \[
              \varphi(\lambda)
              = \det\paren{\lambda E - (P_0^* + \bar q_0 \gamma)}
              = \lambda^m + (\alpha_1 - \gamma_1) \alpha^{m-1} + \cdots +
              (\alpha_m - \gamma_m).
              \]
              </p>

              <p>
              Если эталонный полином
              $\psi(\lambda) = \lambda^n + \beta_1 \lambda^{n-1} + \cdots
              + \beta_n$, то
              \[
              \left\{
              \begin{aligned}
              \beta_1 &= \alpha_1 - \gamma_1 \\
              &\dots \\
              \beta_m &= \alpha_m - \gamma_m
              \end{aligned}
              \right.
              \implies
              \left\{
              \begin{aligned}
              \gamma_1 &= \alpha_1 - \beta_1 \\
              &\dots \\
              \gamma_m &= \alpha_m - \beta_m
              \end{aligned},
              \right.
              \]
              откуда
              \[
              u = \gamma z = \gamma K_0^{-1} y, \implies C = \gamma K_0^{-1}.
              \]
              </p>
            </div>
          </div>
        </div>
      </li>

      <h2 class="subtitle">
        34. Лемма об управлении спектром управляемой подсистемы общего вида
      </h2>

      <li class="question">
        <div class="name">
          Лемма об управлении спектром управляемой подсистемы общего вида
        </div>
        <div class="content">
          Рассмотрим управляемую подсистему
          \[
          \dot{y} = P y + Q u,
          \]
          ищем $u = C y$.

          <div class="lemma">
            Выбором $C$ матрице замкнутой управляемой подсистемы $P + QC$ можно
            обеспечить любой наперёд заданный спектр $\mu_1, \dots, \mu_m$.

            <div class="idea">
              <ol>
                <li>
                  Найти базисные векторы матрицы Калмана:
                  \[
                  Q = (q_1, \dots, q_r),
                  \]
                  выбираем из последовательности
                  \[
                  q_1, P q_1, P^2 q_1, \dots
                  \]
                  первые $n_1$ ЛНЗ. Если не хватает, то выбираем из
                  \[
                  q_2, P q_2, P^2 q_2, \dots
                  \]
                  и так далее. В итоге рассмотрим $l$ последовательностей.
                </li>

                <li>
                  Строим из них матрицу $T$ и проводим замену $y = T z$.
                  Получаем систему
                  \[
                  \dot{z} = \widetilde{P} z + \widetilde{Q} u.
                  \]
                </li>

                <li>
                  Находим матрицу $\widetilde{P} = T^{-1} P T$. Рассматриваем
                  уравнение по столбцам, получаем, что $\widetilde{P}$ &mdash;
                  блочно-диагональная с матрицами Фробениуса на диагонали (для
                  каждого блока все, кроме последнего столбца, соответствуют
                  какому-то базисному вектору, а последний раскладывается в
                  линейную комбинацию базисных).
                </li>

                <li>
                  Найдём матрицу $\widetilde{Q} = T^{-1} Q$. Также
                  рассматриваем по столбцам, получаем, что матрица
                  $\widetilde{Q}$ состоит из блоков $e_k$ по диагонали, где
                  $e_k$ получается из единичной матрицы заменой всех элементов
                  нулями (кроме $e_{kk}$). Если $l = r$, то на этом всё, но
                  если $l \lt r$, то после $l$ диагональных элементов
                  оставшиеся будут раскладываться в линейные комбинации
                  базисных векторов.
                </li>

                <li>
                  Рассмотрим теперь управление
                  $u = C y = C T z = \widetilde{C} z$. Матрица $\widetilde{C}$
                  будет блочно-диагональной &mdash; можно найти из
                  $\widetilde{C} = C T$. Если $l \lt r$, то снизу ещё нулевая
                  матрица добавится.
                </li>

                <li>
                  Подставляя полученные матрицы в систему, находим, что матрица
                  замкнутой системы будет блочно-диагональной с блоками вида
                  $\widetilde{P}^{(k)} - e_k C_1$, причём $\widetilde{P}^{(k)}$
                  &mdash; Фробениуса. Такое уже решали, можем доставить любой
                  спектр каждому блоку на диагонали, следовательно, задача
                  решена.
                </li>
              </ol>
            </div>

            <div class="proof">
              <!-- FIXME: расписать -->
              <span class="todo"></span>
            </div>
          </div>
        </div>
      </li>

      <h2 class="subtitle">
        35. Теорема об условиях существования стабилизирующего управления
      </h2>

      <li class="question">
        <div class="name">
          Теорема об условиях существования стабилизирующего управления
        </div>
        <div class="content">
          Рассмотрим систему в отклонениях
          \[
          \dot{x} = P x + Q u,
          \]
          ищем стабилизирующее управление в виде $u = C x$.

          <div class="theorem">
            Стабилизирующее управление существует тогда и только тогда, когда
            неуправляемая подсистема асимптотически устойчива по Ляпунову, то
            есть собственные числа её матрицы лежат в левой полуплоскости.

            <div class="idea">
              Декомпозируем, получим, что матрица полученной системы блочная,
              значит, её спектр равен объединению спектров каждого блока,
              поэтому если хотя бы одно собственное число матрицы неуправляемой
              системы лежит в правой полуплоскости, то при любом выборе
              управления не получится сделать исходную систему асимптотически
              устойчивой.
            </div>

            <div class="proof">
              <!-- FIXME: расписать -->
              <span class="todo"></span>
            </div>
          </div>
        </div>
      </li>

      <h2 class="subtitle">
        36. Общий алгоритм решения задачи стабилизации
      </h2>

      <li class="question">
        <div class="name">
          Общий алгоритм решения задачи стабилизации
        </div>
        <div class="content">
          <ol>
            <li>
              Строим $T$ &mdash; первые $m$ векторов берём из матрицы Калмана,
              остальными добиваем до базиса
            </li>

            <li>
              Проводим замену $x = T y$.
            </li>

            <li>
              Если есть неуправляемая подсистема, надо её проверить на
              асимптотическую устойчивость.
            </li>

            <li>
              Строим
              \[
              K = \paren{
              \begin{array}{ccccc}
              \alpha_{m - 1} & \alpha_{m-2} & \dots & \alpha_1 & 1 \\
              \alpha_{m-2} & \dots & \alpha_1 & 1 & 0 \\
              \vdots & \rddots & \rddots & \rddots & \vdots \\
              \alpha_1 & 1 & 0 & \dots & 0 \\
              1 & 0 & 0 & \dots & 0
              \end{array}
              }.
              \]
              Если система не ПУ, то справа ещё добавится единичная матрица
              размера $(n-m) \times (n-m)$ для неуправляемой подсистемы.
            </li>

            <li>
              Для каждого блока матрицы $\widetilde{P}$ задаём эталонные
              значения и МНК ищем вектор $\gamma$.
            </li>

            <li>
              Ставим полученные $\gamma_k$ на диагональ матрицы $\Gamma$,
              остальное забиваем нулями до нужной размерности.
            </li>

            <li>
              Искомое управление: $u = C x$, где $C = \Gamma K^{-1} T^{-1}$.
            </li>
          </ol>
        </div>
      </li>

      <h2 class="subtitle">
        37. Стабилизация нелинейных систем по линейному приближению
      </h2>

      <li class="question">
        <div class="name">
          Теорема о стабилизации нелинейной системы по линейному приближению
        </div>
        <div class="content">
          Рассмотрим нелинейную систему в отклонениях:
          \[
          \dot{x} = F(t, x, u).
          \]
          Разложим $F(t, x, u)$ в ряд Маклорена в окрестности точки $0$ и
          выделим линейные слагаемые:
          \[
          \dot{x} = P x + Q u + h(t, x, u).
          \]

          Считаем, что
          <ol>
            <li>
              $h(t, 0, 0) \equiv 0$ &mdash; т.к. система в отклонениях
            </li>

            <li>
              $h(t, x, u) \in C\paren{\norm{x} \leqslant H_1, \norm{u}
              \leqslant H_2 }$, то есть $h$ непрерывна в некоторой окрестности
              точки $0$, причём
              \[
              \norm{h(t, x, u)} \leqslant \alpha
              \paren{\norm{x} + \norm{u}}^{1 + \beta},
              \]
              то есть $h$ имеет порядок малости меньше первого в этой
              окрестности.
            </li>
          </ol>

          Построим линейное приближение:
          \[
          \dot{x}_1 = P x_1 + Q u_1.
          \]

          <div class="theorem">
            Если при управлении $u = C x_1$ линейное приближение асимптотически
            устойчиво, то при управлении $u = C x$ нулевое решение нелинейной
            системы также будет асимптотически устойчиво.

            <div class="idea">
              Используя второй метод Ляпунова, нужно показать, что добавка
              $h(t, x, u)$ в достаточно малой окрестности нуля не портит
              отрицательную определённость производной в силу системы.
            </div>

            <div class="proof">
              <div class="remark">
                Доказательство будем проводить, используя второй метод Ляпунова,
                а именно:
                <div class="theorem">
                  Пусть существует заданная и непрерывно дифференцируемая при
                  $\norm{x} \leqslant H, \; t \geqslant 0$ функция $V(t, x)$,
                  обладающая следующими свойствами
                  <ol>
                    <li>
                      $V(t, x)$ положительно определена
                    </li>

                    <li>
                      $V(t, x)$ допускает бесконечно малый высший предел:
                      <ul>
                        <li>
                          $V(t, 0) \equiv 0$
                        </li>

                        <li>
                          $V(t, x)$ непрерывна по $x$ в точке $x = 0$
                          равномерно по $t \geqslant 0$.
                        </li>
                      </ul>
                    </li>

                    <li>
                      Производная $V(t, x)$ в силу системы отрицательно
                      определена.
                    </li>
                  </ol>

                  Тогда нулевое решение системы равномерно асимптотически
                  устойчиво.
                </div>
              </div>

              Линейное приближение асимптотически устойчиво, а для линейных
              стационарных систем асимптотическая устойчивость эквивалентна
              экспоненциальной устойчивости, поэтому (по теореме об
              экспоненциальной устойчивости) существуют две положительно
              определённые квадратичные формы
              \[
              v(x_1) = x_1^* V x_1 \quad \text{и} \quad w(x_1) = x_1^* W x_1
              \]
              такие, что
              <ol>
                <li>
                  существуют $\alpha_1, \alpha_2, \beta_1, \beta_2 \gt 0$
                  такие, что
                  \[
                  \begin{gathered}
                  \alpha_1 \norm{x_1}^2 \leqslant v(x_1)
                  \leqslant \alpha_2 \norm{x_1}^2\phantom{;} \\
                  \beta_1 \norm{x_1}^2 \leqslant w(x_1)
                  \leqslant \beta_2 \norm{x_1}^2;
                  \end{gathered}
                  \]
                </li>

                <li>
                  и справедливо равенство
                  \[
                  \at{\dv{v(x_1)}{t}}{(*)} = -w(x_1).
                  \]
                </li>
              </ol>

              Для простоты положим $W := E$, то есть $w(x_1) = \norm{x_1}^2$.
              Тогда
              \[
              \begin{aligned}
              \at{\dv{v(x_1)}{t}}{(*)}
              &= x_1^* (P + QC)^* V x_1 + x_1^* V (P + QC) x_1
              = -x_1^* E x_1 \\
              &\implies (P + QC)^* V + V(P + QC) = -E.
              \end{aligned}
              \]
              Получили матричное уравнение Ляпунова, откуда нашли $V$.

              <p>
              Рассмотрим квадратичную форму $v(x) = x^* V x$ с той же матрицей
              $V$. Рассмотрим производную в силу <i>нелинейной</i> системы:
              \[
              \begin{aligned}
              \at{\dv{v(x_1)}{t}}{(1)} &\bydef= \at{\pd{v}{x_1} \dot{x}_1
              + \cdots + \pd{v}{x_n} \dot{x}_n}{(1)} \\
              &= \grad v(x) \cdot \left[(P + QC) x + h(t, x, Cx)\right] \\
              &= \underbrace{\grad v(x) \cdot (P + QC) x}_{= -\norm{x}^2}
              + \grad v(x) \cdot h(t, x, Cx).
              \end{aligned}
              \]
              Оценим $\grad v(x) \cdot h(t, x, Cx)$: из неравенства
              Коши-Буняковского следует
              \[
              \abs{\grad v(x) \cdot h(t, x, Cx)}
              \leqslant \norm{\grad v(x)} \cdot \norm{h(t, x, Cx)}.
              \]
              Так как
              \[
              \begin{aligned}
              \norm{\grad v(x)} &\leqslant 2 \norm{V} \norm{x},
              \quad \text{т.к. } \grad v(x)
              \text{ &mdash; линейная форма} \\
              \norm{h(t, x, u)} &\leqslant \alpha
              \paren{\norm{x} + \norm{C} \norm{x}}^{1 + \beta} \\
              &= \alpha\paren{1 + \norm{C}}^{1 + \beta} \norm{x}^{1 + \beta},
              \end{aligned}
              \]
              поэтому
              \[
              \abs{\grad v(x) \cdot h(t, x, Cx)}
              \leqslant \gamma \norm{x}^{2 + \beta},
              \]
              где
              \[
              \gamma := 2 \alpha \norm{V} \paren{1 + \norm{C}}^{1 + \beta}.
              \]

              Значит,
              \[
              \begin{gathered}
              -\norm{x}^2 - \gamma \norm{x}^{2 + \beta} \leqslant
              \at{\dv{v(x_1)}{t}}{(1)} \leqslant -\norm{x}^2
              + \gamma \norm{x}^{2 + \beta} \\
              -\norm{x}^2 \underbrace{
              \paren{1 + \gamma \norm{x}^{\beta}}
              }_{\geqslant 0}
              \leqslant \at{\dv{v(x_1)}{t}}{(1)} \leqslant
              -\norm{x}^2 \underbrace{
              \paren{1 - \gamma \norm{x}^{\beta}}
              }_{\geqslant 0}.
              \end{gathered}
              \]
              </p>

              <div class="remark">
                Оценка правой части справедлива, т.к. рассматриваем малую
                окрестность точки 0.
              </div>

              <p>
              Значит, производная в силу системы ограничена отрицательно
              определёнными квадратичными формами, поэтому по теореме об
              экспоненциальной устойчивости нулевое решение нелинейной системы
              асимптотически устойчиво.
              </p>
            </div>
          </div>
        </div>
      </li>

      <h2 class="subtitle">
        38. Постановка задачи оптимальной стабилизации. Лемма. Теорема об
        условиях существования оптимального стабилизирующего управления
        (без док-ва)
      </h2>

      <li class="question">
        <div class="name">
          Постановка задачи оптимальной стабилизации
        </div>
        <div class="content">
          Рассмотрим линейную нестационарную систему в отклонениях:
          \[
          \dot{x} = P(t) x + Q(t) u,
          \]
          где
          <ul>
            <li>
              $x \in \mathbb{R}^n, \quad u \in \mathbb{R}^r$;
            </li>

            <li>
              $P(t), Q(t) \in C_{t \geqslant 0}$, ограниченные, вещественные.
            </li>
          </ul>

          <div class="definition">
            Управление
            \[
            u = M(t) x
            \]
            будем считать <i>допустимым</i>, если замкнутая система
            \[
            \dot{x} = (P(t) + Q(t) M(t)) x
            \]
            экспоненциально устойчива.
          </div>

          Введём функционал
          \[
          J = \int\limits_0^\infty W^2 dt,
          \]
          где
          \[
          W^2 := x^* A(t) x + x^* B(t) u + u^* B^*(t) x + u^* C(t) u.
          \]
          Считаем, что $u^* C(t) u$ положительно определена.

          <div class="problem">
            Найти допустимое управление, доставляющее минимум функционалу $J$.
          </div>
        </div>
      </li>

      <li class="question">
        <div class="name">
          Лемма о существовании семейства допустимых стабилизирующих управлений
        </div>
        <div class="content">
          Рассмотрим линейную нестационарную систему в отклонениях:
          \[
          \dot{x} = P(t) x + Q(t) u.
          \]

          <div class="definition">
            Управление
            \[
            u = M(t) x
            \]
            будем считать <i>допустимым</i>, если замкнутая система
            \[
            \dot{x} = (P(t) + Q(t) M(t)) x
            \]
            экспоненциально устойчива.
          </div>

          <div class="lemma">
            Если $u = M(t) x$ &mdash; допустимое управление, то для любой
            вещественной ограниченной непрерывной при $t \geqslant 0$ матрицы
            $N(t)$ управление
            \[
            u = \paren{M(t) + \varepsilon N(t)} x
            \]
            также допустимо при достаточно малом $\varepsilon$.

            <div class="idea">
              Доказывается аналогично случаю стабилизации нелинейных систем
              (через второй метод Ляпунова) &mdash; надо показать, что добавка
              $\varepsilon N(t)$ при достаточно малых $\varepsilon$ не портит
              отрицательную определённость производной в силу системы.
            </div>

            <div class="proof">
              <!-- FIXME: расписать -->
              <span class="todo"></span>
            </div>
          </div>
        </div>
      </li>

      <li class="question">
        <div class="name">
          Теорема об условиях существования оптимального стабилизирующего
          управления (без док-ва)
        </div>
        <div class="content">
          Рассмотрим линейную нестационарную систему в отклонениях:
          \[
          \dot{x} = P(t) x + Q(t) u
          \]
          с заданным функционалом
          \[
          J = \int\limits_0^\infty W^2 dt,
          \]
          где
          \[
          W^2 := x^* A x + x^* B u + u^* B^* x + u^* C u.
          \]


          <div class="theorem">
            Оптимальное стабилизирующее управление $u_0 = M_0(t) x$ для
            $\forall x_0$ существует тогда и только тогда, когда
            <i>матричное уравнение Рикатти</i>
            \[
            \dot{\Theta} - \Theta Q C^{-1} Q^* \Theta + \Theta
            \paren{P - Q C^{-1} B^*} + \paren{P^* - B C^{-1} Q^*} \Theta
            + A - B C^{-1} B^* = 0
            \]
            имеет вещественное, ограниченное, непрерывное при $t \geqslant 0$
            решение в виде такой симметричной матрицы $\Theta(t)$, что
            \[
            u = - C^{-1} (Q^* \Theta + B^*) x
            \]
            является допустимым управлением.
          </div>
        </div>
      </li>

      <h2 class="subtitle">
        39. Метод последовательных приближений Зубова построения оптимального
        стабилизирующего управления. Свойства последовательности приближений.
        Леммы 1-3
      </h2>

      <li class="question">
        <div class="name">
          Метод последовательных приближений Зубова
        </div>
        <div class="content">
          Рассмотрим систему $(1)$ в отклонениях
          \[
          \dot{x} = P(t) x + Q(t) u
          \]
          с заданным функционалом
          \[
          J = \int\limits_0^\infty f(t, x, u) dt.
          \]
          Пусть квадратичная форма $f(t, x, u) = x^* A(t) x + u^* C(t) u$
          положительно определена по $x$ и $u$.

          <p>
          <i>Сущность</i> метода заключается в построении последовательности
          допустимых управлений, сходящихся к оптимальному стабилизирующему.
          </p>

          <h4>Алгоритм</h4>
          <ol>
            <li>
              Возьмём допустимое управление $u_k(t) = M_k(t) x$, замкнём им
              систему:
              \[
              \dot{x} = (P(t) + Q(t) M_k(t)) x.
              \]
              Обозначим её $(*)$.
            </li>

            <li>
              Квадратичная форма в функционале примет вид $f(t, x, u_k)
              = x^* \paren{A + M_k^* C M_k} x$. По условию она положительно
              определена, значит, можно построить квадратичную форму $v_k(t, x)
              = x^* V_k(t) x$ такую, что
              \[
              \at{\dv{v_k(t, x)}{t}}{(*)} = -f(t, x, u_k).
              \]

              <p>
              Распишем:
              \[
              \begin{aligned}
              \at{\dv{v_k(t, x)}{t}}{(*)} &= -f(t, x, u_k) \\
              \dot{V}_k + (P + Q M_k)^* V_k + V_k (P + Q M_k)
              &= -(A + M_k^* C M_k).
              \end{aligned}
              \]
              </p>
            </li>

            <li>
              Пусть $V_k(t)$ &mdash; решение предыдущего уравнения. Рассмотрим
              вспомогательную функцию
              \[
              L_k(u(\cdot)) \bydef= v_k(t, x) + \int\limits_0^t f(t, x, u) dt.
              \]
              Построим управление, <i>оптимальное в смысле демпфирования</i>
              функции $L_k$, то есть доставляющее минимум производной в силу
              незамкнутой системы:
              \[
              \at{\dv{L_k(t, x)}{t}}{(1)} = \at{\dv{v_k(t, x)}{t}}{(1)}
              + f(t, x, u).
              \]
              Можно показать, что точка минимума существует и единственна,
              а оптимальное в смысле демпфирования управление имеет вид
              \[
              \overline u = -C^{-1} Q^* V_k x.
              \]
            </li>

            <li>
              Положим $u_{k+1} := \overline u = -C^{-1} Q^* V_k x$.
            </li>

            <li>
              Вернёмся к шагу 1.
            </li>
          </ol>
        </div>
      </li>

      <li class="question">
        <div class="name">
          Свойства последовательности приближений
        </div>
        <div class="content">
          Рассмотрим систему в отклонениях
          \[
          \dot{x} = P(t) x + Q(t) u
          \]
          с заданным функционалом
          \[
          J = \int\limits_0^\infty f(t, x, u) dt.
          \]
          Пусть квадратичная форма $f(t, x, u) = x^* A(t) x + u^* C(t) u$
          положительно определена по $x$ и $u$.

          <ol>
            <li>
              По построению матрицы $V_k(t)$
              \[
              \at{\dv{v_k(t, x)}{t}}{(1), u=u_k} + f(t, x, u_k) = 0.
              \]
            </li>

            <li>
              Функция
              \[
              L_k(u(\cdot)) \bydef= v_k(t, x) + \int\limits_0^t f(t, x, u) dt
              \]
              убывает наискорейшим образом вдоль решений исходной системы,
              замкнутой управлением, оптимальным в смысле демпфирования, то
              есть $u_{k+1}(t, x)$. Из свойства 1 следует, что
              \[
              \at{\dv{L_k(t, x)}{t}}{(1),u=u_k} = 0, \implies
              \at{\dv{L_k(t, x)}{t}}{(1),u=u_{k+1}} \leqslant 0,
              \]
              откуда получаем
              \[
              \at{\dv{v_k(t, x)}{t}}{(1), u=u_{k+1}} + f(t, x, u_{k+1})
              \leqslant 0.
              \]
            </li>
          </ol>
        </div>
      </li>

      <li class="question">
        <div class="name">
          Последовательные приближения: лемма 1
        </div>
        <div class="content">
          <div class="lemma">
            Если $u_k(t, x)$ допустимо, то $u_{k+1}(t,x)$ &mdash; тоже.

            <div class="idea">
              Следует из свойства 2.
            </div>

            <div class="proof">
              Из свойства 2 следует, что
              \[
              \at{\dv{v_k(t, x)}{t}}{(1), u=u_{k+1}}
              \leqslant -f(t, x, u_{k+1}),
              \]
              но ведь $f(t, x, u)$ &mdash; положительно определённая
              квадратичная форма (по условию), поэтому, по критерию
              экспоненциальной устойчивости, $u_{k+1}(t,x)$ &mdash;
              стабилизирующее управление.
            </div>
          </div>

          <div class="corollary">
            Если $u_1(t,x)$ &mdash; допустимое, то для любого
            $k \in \N$ управление $u_k(t, x)$ также допустимо.
          </div>
        </div>
      </li>

      <li class="question">
        <div class="name">
          Последовательные приближения: лемма 2
        </div>
        <div class="content">
          <div class="lemma">
            Для любого $k \geqslant 0$
            \[
            v_{k+1}(t, x) \leqslant v_k(t, x)
            \]
            при всех $t \geqslant 0$.

            <div class="idea">
              Следует из свойств 1 и 2.
            </div>

            <div class="proof">
              Из свойств 1 и 2 следует, что
              \[
              \left\{
              \begin{aligned}
              &\at{\dv{v_{k+1}(t, x)}{t}}{(1), u=u_{k+1}} + f(t, x, u_{k+1})
              = 0 \\
              &\at{\dv{v_k(t, x)}{t}}{(1), u=u_{k+1}} + f(t, x, u_{k+1})
              \leqslant 0,
              \end{aligned}
              \right.
              \]
              поэтому
              \[
              \at{\dv{}{t} \paren{v_{k+1}(t, x) - v_k(t, x)}}{(1), u=u_k}
              \geqslant 0.
              \]

              Найдём решение $x = x(t, t_0, x_0)$ системы при $u = u_{k+1}$
              для произвольных начальных условий, тогда
              \[
              \at{\dv{}{t} \paren{
              v_{k+1}(t, x(t, t_0, x_0)) - v_k(t, x(t, t_0, x_0))
              }}{(1), u=u_k}
              \geqslant 0.
              \]
              Проинтегрируем от $t_0$ до $T$:
              \[
              \left[
              v_{k+1} \paren{T, x(T, t_0, x_0)} - v_k \paren{T, x(T, t_0, x_0)}
              \right]
              -
              \left[
              v_{k+1} \paren{t_0, x_0} - v_k \paren{t_0, x_0}
              \right]
              \geqslant 0.
              \]
              Первое слагаемое стремится к нулю при $T \to \infty$, т.к.
              решение $x = x(t, t_0, x_0) \to 0$ в силу экспоненциальной
              устойчивости, а $v_k$ и $v_{k+1}$ &mdash; положительно
              определённые квадратичные формы.

              <p>
              Получается, что
              \[
              -
              \left[
              v_{k+1} \paren{t_0, x_0} - v_k \paren{t_0, x_0}
              \right]
              \geqslant 0.
              \]
              откуда в силу произвольности $t_0, x_0$ и $k$ следует, что
              \[
              v_{k+1}(t, x) \leqslant v_k(t, x).
              \]
              </p>
            </div>
          </div>
        </div>
      </li>

      <li class="question">
        <div class="name">
          Последовательные приближения: лемма 3
        </div>
        <div class="content">
          <div class="lemma">
            Если $u_1(t, x)$ &mdash; допустимое управление, то существуют
            $\alpha_1, \alpha_2, \beta_1, \beta_2 \gt 0$ такие, что
            $\forall k \in \N$ для любого решения системы с управлением
            $u = u_k(t,x)$ при $t \geqslant t_0$ справедливо:
            \[
            \alpha_1 \norm{x_0} e^{-\beta_1 (t - t_0)}
            \leqslant \norm{x(t, t_0, x_0)} \leqslant
            \alpha_2 \norm{x_0} e^{-\beta_2 (t - t_0)}.
            \]
          </div>
        </div>
      </li>

      <h2 class="subtitle">
        40. Теорема о сходимости последовательности приближений
      </h2>

      <li class="question">
        <div class="name">
          Теорема о сходимости последовательности приближений
        </div>
        <div class="content">
          <div class="theorem">
            Если $f(t, x, u)$ положительно определена, а $u_1(t,x)$ допустимо,
            то последовательность $u_k$ сходится к $u_0$ равномерно:
            \[
            \set{u_k(t, x)} \underset{\displaystyle \to}{\to} u_0(t, x).
            \]

            <div class="idea">
              <p>
              Надо доказать, что последовательность
              \[
              \set{V_k(t)} \underset{k \to \infty}{\longrightarrow} V_0(t).
              \]
              Проверяем сначала сходимость диагональных элементов, потом
              недиагональных.
              </p>

              <p>
              Если
              \[
              \set{V_k(t)} \underset{k \to \infty}{\longrightarrow} V_0(t),
              \]
              то
              \[
              M_k(t) = -C^{-1} Q^* V_k(t)
              \underset{k \to \infty}{\longrightarrow}
              M_0(t) = -C^{-1} Q^* V_0(t).
              \]
              </p>

              <p>
              Проверим допустимость. Из леммы 3 следует экспоненциальная
              устойчивость левой части
              \[
              M_k(t) = -C^{-1} Q^* V_k(t)
              \underset{k \to \infty}{\longrightarrow}
              M_0(t) = -C^{-1} Q^* V_0(t),
              \]
              значит, следует и правая.
              </p>

              <p>
              Проверим оптимальность. Достаточно показать, что $V_0(t)$
              удовлетворяет уравнению Риккати. Так как $V_k(t)$ &mdash; решение
              матричного уравнения Ляпунова, то
              \[
              \dot{V}_k + (P + Q M_k)^* V_k + V_k (P + Q M_k)
              = -(A + M_k^* C M_k)
              \underset{k \to \infty}{\longrightarrow}
              \dot{V}_0 + (P + Q M_0)^* V_0 + V_0 (P + Q M_0)
              = -(A + M_0^* C M_0).
              \]
              Подставляя $M_0(t) = -C^{-1} Q^* V_0(t)$, получаем уравнение
              Риккати:
              \[
              \dot{V}_0 + P^* V_0 + V_0 P + A - V_0 Q C^{-1} Q^* V_0 = 0.
              \]
              </p>
            </div>

            <div class="proof">
              <!-- FIXME: расписать -->
              <span class="todo"></span>
            </div>
          </div>
        </div>
      </li>
    </ol>
  </body>

</html>

